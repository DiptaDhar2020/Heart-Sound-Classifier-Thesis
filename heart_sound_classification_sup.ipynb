{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiptaDhar2020/Heart-Sound-Classifier-Thesis/blob/main/heart_sound_classification_sup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d814d458",
      "metadata": {
        "id": "d814d458"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98dccb3e",
      "metadata": {
        "id": "98dccb3e"
      },
      "outputs": [],
      "source": [
        "data_path=\"C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Heart Sound Classification\\\\set_a\"\n",
        "set_a=pd.read_csv(\"set_a.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7263be52",
      "metadata": {
        "scrolled": false,
        "id": "7263be52",
        "outputId": "592133df-b0a1-4ed3-cf05-b2798ec5447b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>artifact__201012172012.wav</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>artifact__201105040918.wav</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>artifact__201105041959.wav</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>artifact__201105051017.wav</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>artifact__201105060108.wav</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        fname     label\n",
              "0  artifact__201012172012.wav  artifact\n",
              "1  artifact__201105040918.wav  artifact\n",
              "2  artifact__201105041959.wav  artifact\n",
              "3  artifact__201105051017.wav  artifact\n",
              "4  artifact__201105060108.wav  artifact"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_a.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dabc98c7",
      "metadata": {
        "collapsed": true,
        "id": "dabc98c7",
        "outputId": "b6eeaed6-c082-4ce4-cf8f-c8ac8dd28c9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10428\\3080665856.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Heart Sound Classification\\\\my_heartbeat.wav\\\\artifact__201012172012.wav'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
            "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Heart Sound Classification\\\\my_heartbeat.wav\\\\artifact__201012172012.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     25\u001b[0m         full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(wav_dir, filename)\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mpad_wav_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll WAV files have been padded to 5 seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mpad_wav_file\u001b[1;34m(data_path, desired_length)\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m index_num,row \u001b[38;5;129;01min\u001b[39;00m tqdm(set_a\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[0;32m      5\u001b[0m       file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(data_path), \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m----> 6\u001b[0m       audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkaiser_fast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate the number of samples needed for the desired length\u001b[39;00m\n\u001b[0;32m      9\u001b[0m   desired_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sample_rate \u001b[38;5;241m*\u001b[39m desired_length)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:60\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     59\u001b[0m )\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:241\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    238\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    244\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Heart Sound Classification\\\\my_heartbeat.wav\\\\artifact__201012172012.wav'"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "def pad_wav_file(data_path, desired_length=5):\n",
        "  # Load the audio data\n",
        "    for index_num,row in tqdm(set_a.iterrows()):\n",
        "        file_name = os.path.join(os.path.abspath(data_path), str(row[\"fname\"]))\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "\n",
        "  # Calculate the number of samples needed for the desired length\n",
        "    desired_samples = int(sample_rate * desired_length)\n",
        "\n",
        "  # Pad the data with silence\n",
        "    if len(audio) < desired_samples:\n",
        "        padding = np.zeros((desired_samples - len(audio), ))\n",
        "        audio = np.concatenate((audio, padding))\n",
        "\n",
        "  # Save the padded data to a new WAV file\n",
        "    librosa.output.write_wav(f\"{data_path}_padded.wav\", audio, sample_rate)\n",
        "\n",
        "# Set the directory containing your WAV files\n",
        "wav_dir = \"C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Heart Sound Classification\"\n",
        "\n",
        "# Pad all WAV files in the directory\n",
        "for filename in os.listdir(wav_dir):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        full_path = os.path.join(wav_dir, filename)\n",
        "        pad_wav_file(full_path)\n",
        "\n",
        "print(\"All WAV files have been padded to 5 seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115451d6",
      "metadata": {
        "id": "115451d6"
      },
      "outputs": [],
      "source": [
        "def features_extractor(file):\n",
        "    audio, fs = librosa.load(file_name, res_type='kaiser_fast')\n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    return mfccs_scaled_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d41677",
      "metadata": {
        "id": "82d41677",
        "outputId": "2f70ab56-c000-4082-fb78-5ae5935eb313"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "585it [01:09,  8.43it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "### Now we iterate through every audio file and extract features\n",
        "### using Mel-Frequency Cepstral Coefficients\n",
        "extracted_features=[]\n",
        "for index_num,row in tqdm(set_a.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(data_path), str(row[\"fname\"]))\n",
        "    final_class_labels=row[\"label\"]\n",
        "    data=features_extractor(file_name)\n",
        "    extracted_features.append([data,final_class_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03ba0e7",
      "metadata": {
        "id": "a03ba0e7"
      },
      "outputs": [],
      "source": [
        "#for padding\n",
        "from tqdm import tqdm\n",
        "for index_num,row in tqdm(set_a.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(data_path), str(row[\"fname\"]))\n",
        "    final_class_labels=row[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90fe6dde",
      "metadata": {
        "id": "90fe6dde",
        "outputId": "475a47ed-f498-46d9-fab3-213adfabacc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-594.4451, 39.270527, 4.9519215, 6.193456, 2....</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-755.9029, 36.831474, -11.583059, 4.488951, -...</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-567.8288, 47.297626, -24.984045, 7.8763213, ...</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-299.02612, 111.469696, -20.94014, 27.45851, ...</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-295.5859, 101.416336, -17.657728, 14.551581,...</td>\n",
              "      <td>artifact</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature     label\n",
              "0  [-594.4451, 39.270527, 4.9519215, 6.193456, 2....  artifact\n",
              "1  [-755.9029, 36.831474, -11.583059, 4.488951, -...  artifact\n",
              "2  [-567.8288, 47.297626, -24.984045, 7.8763213, ...  artifact\n",
              "3  [-299.02612, 111.469696, -20.94014, 27.45851, ...  artifact\n",
              "4  [-295.5859, 101.416336, -17.657728, 14.551581,...  artifact"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### converting extracted_features to Pandas dataframe\n",
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','label'])\n",
        "extracted_features_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e419a35",
      "metadata": {
        "id": "0e419a35"
      },
      "outputs": [],
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['label'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db77fe3",
      "metadata": {
        "id": "4db77fe3",
        "outputId": "765b4e15-2663-4a90-a0e9-38a3abd3efe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(585, 40)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb707ee",
      "metadata": {
        "id": "cbb707ee",
        "outputId": "024472f5-af3a-4ca1-99a6-b00fbb17cf39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(585,)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066d9580",
      "metadata": {
        "id": "066d9580"
      },
      "outputs": [],
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8218aefb",
      "metadata": {
        "id": "8218aefb",
        "outputId": "9adc138d-4ce8-4ce8-b339-5ed5d3db722a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73.50427350427351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logi_reg=LogisticRegression()\n",
        "logi_reg.fit(X_train, y_train)\n",
        "ypred_logi=logi_reg.predict(X_test)\n",
        "acc_logi=accuracy_score(y_test,ypred_logi)\n",
        "print(acc_logi*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2381f44b",
      "metadata": {
        "id": "2381f44b",
        "outputId": "33323bfc-0c22-4fff-d48b-f4967de6f99d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    artifact       1.00      0.90      0.95        10\n",
            "     extrahs       0.50      0.40      0.44         5\n",
            "extrasystole       0.00      0.00      0.00         7\n",
            "      murmur       0.80      0.41      0.55        29\n",
            "      normal       0.71      0.95      0.81        66\n",
            "\n",
            "    accuracy                           0.74       117\n",
            "   macro avg       0.60      0.53      0.55       117\n",
            "weighted avg       0.70      0.74      0.69       117\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(classification_report(y_test,ypred_logi))\n",
        "confusion_matrix = metrics.confusion_matrix(y_test,ypred_logi)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(\n",
        "    confusion_matrix=confusion_matrix,\n",
        "    display_labels=['artifact', 'extrahs', 'extrasystole', 'murmur', 'normal'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229c17b4",
      "metadata": {
        "id": "229c17b4",
        "outputId": "d77781d4-7acf-4e7b-a781-c4a4329b1d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76.06837606837607\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "mod_RF=RandomForestClassifier()\n",
        "mod_RF.fit(X_train,y_train)\n",
        "pred_RF=mod_RF.predict(X_test)\n",
        "acc_RF=accuracy_score(y_test,pred_RF)\n",
        "print(acc_RF*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd083f3a",
      "metadata": {
        "id": "cd083f3a",
        "outputId": "0d8922fc-3e56-465b-9043-dc5b69d546f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    artifact       1.00      1.00      1.00        10\n",
            "     extrahs       0.67      0.40      0.50         5\n",
            "extrasystole       0.00      0.00      0.00         7\n",
            "      murmur       0.78      0.48      0.60        29\n",
            "      normal       0.73      0.95      0.83        66\n",
            "\n",
            "    accuracy                           0.76       117\n",
            "   macro avg       0.64      0.57      0.58       117\n",
            "weighted avg       0.72      0.76      0.72       117\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(classification_report(y_test,pred_RF))\n",
        "confusion_matrix = metrics.confusion_matrix(y_test,pred_RF)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(\n",
        "    confusion_matrix=confusion_matrix,\n",
        "    display_labels=['artifact', 'extrahs', 'extrasystole', 'murmur', 'normal'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d604a9f1",
      "metadata": {
        "id": "d604a9f1",
        "outputId": "a17179a3-fd0e-4bca-93ec-fc31c16d9159"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71.7948717948718\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "mod_ada=AdaBoostClassifier(n_estimators=90, learning_rate=0.5, algorithm='SAMME.R')\n",
        "mod_ada.fit(X_test,y_test)\n",
        "mod_ada.score(X_test, y_test)\n",
        "pred_ada=mod_ada.predict(X_test)\n",
        "acc_ada=accuracy_score(y_test, pred_ada)\n",
        "print(acc_ada*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c25864",
      "metadata": {
        "id": "75c25864",
        "outputId": "b108190f-9b73-49dc-9687-1d258f71d8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    artifact       1.00      0.90      0.95        10\n",
            "     extrahs       0.83      1.00      0.91         5\n",
            "extrasystole       1.00      0.14      0.25         7\n",
            "      murmur       0.67      0.21      0.32        29\n",
            "      normal       0.68      0.95      0.80        66\n",
            "\n",
            "    accuracy                           0.72       117\n",
            "   macro avg       0.84      0.64      0.64       117\n",
            "weighted avg       0.73      0.72      0.66       117\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(classification_report(y_test, pred_ada))\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, pred_ada)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(\n",
        "    confusion_matrix=confusion_matrix,\n",
        "    display_labels=['artifact', 'extrahs', 'extrasystole', 'murmur', 'normal'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a51261",
      "metadata": {
        "id": "b5a51261",
        "outputId": "02b61a3a-5dc9-44d6-df79-f1e7e2b7a96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73.50427350427351\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "mod_svc=SVC(kernel='linear', probability=True, C=1.0, cache_size=500)\n",
        "mod_svc.fit(X_train, y_train)\n",
        "pred_svc=mod_svc.predict(X_test)\n",
        "acc_svc=accuracy_score(y_test, pred_svc)\n",
        "print(acc_svc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "897d997f",
      "metadata": {
        "id": "897d997f",
        "outputId": "25935ef9-c07a-4eb7-bfeb-4492d92a11b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    artifact       0.89      0.80      0.84        10\n",
            "     extrahs       1.00      0.20      0.33         5\n",
            "extrasystole       0.00      0.00      0.00         7\n",
            "      murmur       0.78      0.48      0.60        29\n",
            "      normal       0.71      0.95      0.81        66\n",
            "\n",
            "    accuracy                           0.74       117\n",
            "   macro avg       0.67      0.49      0.52       117\n",
            "weighted avg       0.71      0.74      0.69       117\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGwCAYAAACpYG+ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfgklEQVR4nO3deXxM9/4/8NfJNlknu0SIhCYhIbEWQSWIRlVKuaiqrUrtQmPJvRVBK71a+7W3gluK2n5VpUVrKaGk0lpDRCRK7ElEZJv5/P7IN3M7JpiYJDPJvJ6Px3k8nM+ccz7v+WRk3vks50hCCAEiIiIiI2Ci7wCIiIiIqgoTHyIiIjIaTHyIiIjIaDDxISIiIqPBxIeIiIiMBhMfIiIiMhpMfIiIiMhomOk7AKpaSqUSN2/ehJ2dHSRJ0nc4RERUDkIIPHr0CB4eHjAxqby+i/z8fBQWFup8HQsLC1haWlZARBWHiY+RuXnzJjw9PfUdBhER6SAjIwN169atlGvn5+ejvpctMu8odL6Wu7s7rl27ZlDJDxMfI2NnZwcACPEbDzNTmZ6jMWyKi1f0HQKR0TGxsdZ3CAatWBThSN421e/yylBYWIjMOwpcT/SG3O7le5VyHinh1TINhYWFTHxIf0qHt8xMZUx8XkCSzPUdApHRMZEs9B1CtVAVUxVs7STY2r18PUoY5nQKJj5ERESkQSGUUOjwNE+FUFZcMBWIiQ8RERFpUEJAiZfPfHQ5tzJxOTsREREZDfb4EBERkQYllNBlsEq3sysPEx8iIiLSoBACCvHyw1W6nFuZONRFRERERoM9PkRERKShpk5uZuJDREREGpQQUNTAxIdDXURERGQ02ONDREREGjjURUREREaDq7qIiIiIKtFff/2F9957D87OzrCyskJgYCBOnz6tel0IgZiYGNSuXRtWVlYICwvDlSvle6A0Ex8iIiLSoKyArTwePnyI9u3bw9zcHHv37sWFCxcwf/58ODo6qo6ZN28elixZgpUrV+LkyZOwsbFBeHg48vPzta6HQ11ERESkQaHjqq7ynvvvf/8bnp6eiI+PV5XVr19f9W8hBBYtWoSPP/4YPXv2BABs2LABbm5u2LVrF9555x2t6mGPDxEREWlQCN03AMjJyVHbCgoKyqzvu+++Q6tWrdC3b1/UqlULzZs3x5o1a1SvX7t2DZmZmQgLC1OV2dvbo02bNkhISND6fTHxISIiokrj6ekJe3t71RYXF1fmcampqVixYgV8fX3x448/YvTo0ZgwYQLWr18PAMjMzAQAuLm5qZ3n5uamek0bHOoiIiIiDS8zT+fp8wEgIyMDcrlcVS6Tyco+XqlEq1atMHfuXABA8+bNce7cOaxcuRJDhgzRIRJ17PEhIiIiDUpIUOiwKSEBAORyudr2rMSndu3aCAgIUCvz9/dHeno6AMDd3R0AcPv2bbVjbt++rXpNG0x8iIiISO/at2+P5ORktbLLly/Dy8sLQMlEZ3d3dxw8eFD1ek5ODk6ePIng4GCt6+FQFxEREWlQipJNl/PLY9KkSWjXrh3mzp2Lfv364bfffsPq1auxevVqAIAkSYiMjMQnn3wCX19f1K9fHzNmzICHhwd69eqldT1MfIiIiEhD6ZCVLueXx6uvvoqdO3ciOjoas2fPRv369bFo0SIMHDhQdczUqVPx+PFjjBw5EllZWejQoQP27dsHS0tLreuRhDDQe0pTpcjJyYG9vT26+EfBzLTscVYqoTif/OKDiKhCmdjY6DsEg1YsCvHz42+QnZ2tNmG4IpV+T5w87w5bu5efEZP7SIk2jTMrNdaXwR4fIiIi0lDVPT5VhYkPERERaVAKCUrx8smLLudWJq7qIiIiIqPBHh8iIiLSwKEuIiIiMhoKmEChw8CQogJjqUhMfIiIiEiD0HGOj+AcHyIiIiL9Yo9PJfD29kZkZCQiIyMBlDxRdtCgQTh+/DjMzc2RlZWl1/gMgYmJEgMHnUenLulwdMrHg/uWOPCTN77ZGAAY6LiwPkUMvYd/jL4DJ9dipF6wwvKP6yA5yVrfYRkctpN22E7P1+/DG2j/+n3UbfAEhQUmuPC7HGs/98Jf16z0HVqVqqlzfNjjo4N169bBwcFBo/zUqVMYOXKkan/hwoW4desWkpKScPny5QqpOzQ0VJVYVUf/6H8J3SOuYsV/muPD4d2w9ssg9OmXjLd6XdF3aAYn5K2HGDnzJjYucMfYcD+kXrDEp5tSYe9cpO/QDArbSTtspxcLbJ2D3RtrY1LfIPxzaGOYmSvxafx5yKwMddZK5VAIE503Q2SYUVUDRUXP/iXh6uoKa+v//fV09epVtGzZEr6+vqhVq1ZVhGfwAgLu48TxOjj1mwfu3LbBsaOeOJPoBr+GD/QdmsHpPfIe9m1ywk9bnJB+xRJLptVFwRMJ4QPYVn/HdtIO2+nFZgwPwIEdtZCeYo1rl2ywYJov3OoUwrdJrr5DowrAxOf/7Nu3Dx06dICDgwOcnZ3Ro0cPXL16FQCQlpYGSZKwZcsWhISEwNLSEhs3bsSwYcOQnZ0NSZIgSRJiY2MBlAx1LVq0SPXv7du3Y8OGDZAkCUOHDgUALFiwAIGBgbCxsYGnpyfGjBmD3Fz1/1THjh1DaGgorK2t4ejoiPDwcDx8+BBDhw7F4cOHsXjxYlXdaWlpVdRSFePCBWc0a34bdeo8AgDUb5CFgCb3cPpUbT1HZljMzJXwDcrD70ftVGVCSDhz1A4BLfP0GJlhYTtph+30cqxtiwEAj7KMa3aIEhKUMNFhM8yhLuP6KT7H48ePMXnyZAQFBSE3NxcxMTF4++23kZSUpDpm+vTpmD9/Ppo3bw4TExMsWrQIMTExSE4ueaaTra2txnVPnTqFwYMHQy6XY/HixbCyKhkjNjExwZIlS1C/fn2kpqZizJgxmDp1KpYvXw4ASEpKQpcuXfD+++9j8eLFMDMzwy+//AKFQoHFixfj8uXLaNKkCWbPng2gpJepLAUFBSgoKFDt5+TkVEh76erbzf6wti7GqrV7oVRKMDER2BAfiEM/e+k7NIMid1LA1AzIuqv+X/XhPTN4+hQ84yzjw3bSDtup/CRJ4MOP03D+tB2uXzGu54jV1Dk+THz+T58+fdT2165dC1dXV1y4cEGV0ERGRqJ3796qY+zt7SFJEtzd3Z95XVdXV8hkMlhZWakd9/f5Od7e3vjkk08watQoVeIzb948tGrVSrUPAI0bN1b928LCAtbW1s+tGwDi4uIwa9as5x6jD6+FZKBT5+uYF9cW6WlyNPDJwsjRSbh/3woH93vrOzwiIgDA2NhUePvmIWpAE32HQhWEQ13/58qVKxgwYAAaNGgAuVwOb29vAEB6errqmFatWlVYfQcOHECXLl1Qp04d2NnZYdCgQbh//z7y8kq6m0t7fHQVHR2N7Oxs1ZaRkaHzNSvC8BF/4NstjXDkUD2kpTng5wPe2LXdD/3euajv0AxKzgNTKIoBB9ditXJHl2I8vMu/W0qxnbTDdiqf0TGpaN3pIaYNaox7mTJ9h1PlOLm5houIiMCDBw+wZs0anDx5EidPngQAFBYWqo6xsamYbs60tDT06NEDQUFB2L59OxITE7Fs2TK1+kqHxHQlk8kgl8vVNkMgs1RAqVTvBi0d8qL/KS4ywZU/rdG8wyNVmSQJNOuQiwuJXH5ciu2kHbaTtgRGx6SiXdcHmD6oMW7fsNR3QHpRMsdHt80QMfEBcP/+fSQnJ+Pjjz9Gly5d4O/vj4cPH77wPAsLCygU5V/emJiYCKVSifnz56Nt27bw8/PDzZs31Y4JCgrCwYMHK7xuQ3HyhAfeefciXm19E7XcHiO4/Q283ecyjh+ro+/QDM6O1S54490HCOv7AJ4++Rj/2Q1YWivx02YnfYdmUNhO2mE7vdjY2FR07nkX8z7yxZPHpnB0KYSjSyEsZNX3dy79D/s2ATg6OsLZ2RmrV69G7dq1kZ6ejunTp7/wPG9vb+Tm5uLgwYNo2rQprK2t1ZaxP4uPjw+KioqwdOlSRERE4NixY1i5cqXaMdHR0QgMDMSYMWMwatQoWFhY4JdffkHfvn3h4uICb29vnDx5EmlpabC1tYWTkxNMTKpPHrvyP80xaOg5jJ3wO+wdCvDgviX27mmATV8H6Ds0g3P4O0fYOysweEomHF2LkXreCv8aWB9Z98z1HZpBYTtph+30Yj0G3gYAzNt4Xq18/jQfHNhhPLckUer4rC4lDLMHn4kPSlZYbd68GRMmTECTJk3QsGFDLFmyBKGhoc89r127dhg1ahT69++P+/fvY+bMmaol7c/TtGlTLFiwAP/+978RHR2Njh07Ii4uDoMHD1Yd4+fnh59++gn//Oc/0bp1a1hZWaFNmzYYMGAAACAqKgpDhgxBQEAAnjx5gmvXrqnmJVUHT56YY/WK5li9orm+Q6kWvot3wXfxLvoOw+CxnbTDdnq+N3zb6TsEg6DrPB2FMMzERxLCQCOjSpGTkwN7e3t08Y+CmanxTdYrD8X5ZH2HQGR0TCpoLmVNVSwK8fPjb5CdnV1pczZLvyc2JTWBtZ3pS18n75EC7zY7V6mxvozqMzZCREREpCMOdREREZEGhZCgEDrcwFCHcysTEx8iIiLSoNBxcrPCQCc3c6iLiIiIjAZ7fIiIiEiDUphAqcOqLqWBrp1i4kNEREQaONRFREREVM2xx4eIiIg0KKHbyixlxYVSoZj4EBERkQYlTKDU6ZEVhjmoZJhREREREVUC9vgQERGRBt2f1WWYfStMfIiIiEiDEhKU0GWOD+/cTERERNVETe3xMcyoiIiIiCoBe3yIiIhIg+43MDTMvhUmPkRERKRBKSQodbmPj4E+nd0w0zEiIiKiSsAeHyIiItKg1HGoy1BvYMjEh4iIiDTo/nR2w0x8DDMqIiIiokrAHh8iIiLSoIAEhQ43IdTl3MrExIeIiIg0cKiLiIiIqJpjjw8RERFpUEC34SpFxYVSoZj4EBERkYaaOtTFxIeIiIg08CGlRERERNUce3yIiIhIg4AEpQ5zfASXsxMREVF1waEuIiIiokoSGxsLSZLUtkaNGqlez8/Px9ixY+Hs7AxbW1v06dMHt2/fLnc97PExUoqLVyBJ5voOw6BJ5hb6DqFaEEWF+g6hWjCxsdF3CETlohQSlOLlh6te5tzGjRvjwIEDqn0zs/+lKZMmTcKePXvw7bffwt7eHuPGjUPv3r1x7NixctXBxIeIiIg0KHR8OnvpuTk5OWrlMpkMMpmszHPMzMzg7u6uUZ6dnY2vvvoKmzZtQufOnQEA8fHx8Pf3x4kTJ9C2bVut4+JQFxEREVUaT09P2Nvbq7a4uLhnHnvlyhV4eHigQYMGGDhwINLT0wEAiYmJKCoqQlhYmOrYRo0aoV69ekhISChXPOzxISIiIg0VNdSVkZEBuVyuKn9Wb0+bNm2wbt06NGzYELdu3cKsWbPw2muv4dy5c8jMzISFhQUcHBzUznFzc0NmZma54mLiQ0RERBqUMIFSh4Gh0nPlcrla4vMsb7zxhurfQUFBaNOmDby8vLB161ZYWVm9dBxP41AXERERGRwHBwf4+fkhJSUF7u7uKCwsRFZWltoxt2/fLnNO0PMw8SEiIiINCiHpvOkiNzcXV69eRe3atdGyZUuYm5vj4MGDqteTk5ORnp6O4ODgcl2XQ11ERESkoaqXs0dFRSEiIgJeXl64efMmZs6cCVNTUwwYMAD29vYYPnw4Jk+eDCcnJ8jlcowfPx7BwcHlWtEFMPEhIiKiMggdn84uynnujRs3MGDAANy/fx+urq7o0KEDTpw4AVdXVwDAwoULYWJigj59+qCgoADh4eFYvnx5ueNi4kNERER6t3nz5ue+bmlpiWXLlmHZsmU61cPEh4iIiDQoIEGhw4NGdTm3MjHxISIiIg1K8XKPnfj7+YaIq7qIiIjIaLDHh4iIiDQodZzcrMu5lYmJDxEREWlQQoJSh3k6upxbmQwzHSMiIiKqBOzxISIiIg263n1Z1zs3VxYmPkRERKShps7xMcyoiIiIiCoBe3yIiIhIgxI6PqvLQCc3M/EhIiIiDULHVV2CiQ8RERFVF1X9dPaqwjk+REREZDTY40NEREQaauqqLiY+REREpIFDXURERETVHHt8iIiISENNfVYXEx8iIiLSwKEuIiIiomqOPT5ERESkoab2+DDxISIiIg01NfHhUBcREREZDfb4GJB169YhMjISWVlZ+g6lykQMvYd/jL4DJ9dipF6wwvKP6yA5yVrfYRmUJq0f4R8f3oJvYB6c3Yowa4QPEn5y1HdYBomfp+fr9+ENtH/9Puo2eILCAhNc+F2OtZ974a9rVvoOzaCwnUqwx4c0HDp0CJIkGVWiUpFC3nqIkTNvYuMCd4wN90PqBUt8uikV9s5F+g7NoFhaK3DtojWWzfDSdygGjZ+nFwtsnYPdG2tjUt8g/HNoY5iZK/Fp/HnIrBT6Ds2gsJ1KCPxvSfvLbELfb+AZmPhUgcLCQn2HYJB6j7yHfZuc8NMWJ6RfscSSaXVR8ERC+IAH+g7NoJw+5ID1X9TF8R/Zy/M8/Dy92IzhATiwoxbSU6xx7ZINFkzzhVudQvg2ydV3aAaF7VSitMdHl80QGX3io1QqERcXh/r168PKygpNmzbFtm3bIIRAWFgYwsPDIURJ3vrgwQPUrVsXMTExSEtLQ6dOnQAAjo6OkCQJQ4cOBQCEhoZi3LhxiIyMhIuLC8LDwwEACxYsQGBgIGxsbODp6YkxY8YgN1fzP9KPP/4If39/2Nraolu3brh165bqtUOHDqF169awsbGBg4MD2rdvj+vXr1dyK1U8M3MlfIPy8PtRO1WZEBLOHLVDQMs8PUZG1RE/Ty/H2rYYAPAoi7MenoftVLMYfeITFxeHDRs2YOXKlTh//jwmTZqE9957D0eOHMH69etx6tQpLFmyBAAwatQo1KlTBzExMfD09MT27dsBAMnJybh16xYWL16suu769ethYWGBY8eOYeXKlQAAExMTLFmyBOfPn8f69evx888/Y+rUqWrx5OXl4YsvvsB///tfHDlyBOnp6YiKigIAFBcXo1evXggJCcGff/6JhIQEjBw5EpL07Ky6oKAAOTk5apshkDspYGoGZN1V/0Xy8J4ZHF2L9RQVVVf8PJWfJAl8+HEazp+2w/UrNvoOx2AZczvV1B4fo05fCwoKMHfuXBw4cADBwcEAgAYNGuDXX3/FqlWrsGnTJqxatQqDBw9GZmYmfvjhB5w5cwZmZiXN5uTkBACoVasWHBwc1K7t6+uLefPmqZVFRkaq/u3t7Y1PPvkEo0aNwvLly1XlRUVFWLlyJV555RUAwLhx4zB79mwAQE5ODrKzs9GjRw/V6/7+/s99j3FxcZg1a1Y5W4aIarqxsanw9s1D1IAm+g7FoBlzO9XUyc1GnfikpKQgLy8PXbt2VSsvLCxE8+bNAQB9+/bFzp078dlnn2HFihXw9fXV6totW7bUKDtw4ADi4uJw6dIl5OTkoLi4GPn5+cjLy4O1dcnKE2tra1VSAwC1a9fGnTt3AJQkWkOHDkV4eDi6du2KsLAw9OvXD7Vr135mHNHR0Zg8ebJqPycnB56enlq9h8qU88AUimLA4am/xh1divHwrlF/LOkl8PNUPqNjUtG600NMebcJ7mXK9B2OwWI71UxGPdRVOr9mz549SEpKUm0XLlzAtm3bAJQMPSUmJsLU1BRXrlzR+to2NupdomlpaejRoweCgoKwfft2JCYmYtmyZQDUJz+bm5urnSdJkmqOEQDEx8cjISEB7dq1w5YtW+Dn54cTJ048Mw6ZTAa5XK62GYLiIhNc+dMazTs8UpVJkkCzDrm4kMjlx1Q+/DxpS2B0TCradX2A6YMa4/YNS30HZKDYTgCHumqkgIAAyGQypKenIyQkpMxjPvroI5iYmGDv3r3o3r073nzzTXTu3BkAYGFhAQBQKF68xDExMRFKpRLz58+HiUlJvrl169aXirt58+Zo3rw5oqOjERwcjE2bNqFt27YvdS192rHaBVGLMnD5D2skn7HG2yPuwtJaiZ82O+k7NINiaa2Ah3eBat/dswANAvLwKMsUd2/yr9BS/Dy92NjYVIRG3MPs0Y3w5LEpHF1K/uh6/MgUhQWmeo7OcLCdSgghQeiQvOhybmUy6sTHzs4OUVFRmDRpEpRKJTp06IDs7GwcO3YMcrkcLi4uWLt2LRISEtCiRQtMmTIFQ4YMwZ9//glHR0d4eXlBkiR8//336N69O6ysrGBra1tmXT4+PigqKsLSpUsRERGhNulZW9euXcPq1avx1ltvwcPDA8nJybhy5QoGDx5cEc1R5Q5/5wh7ZwUGT8mEo2sxUs9b4V8D6yPrnvmLTzYifkGPMW9Lsmr/w5gMAMD+b50xP6qBvsIyOPw8vViPgbcBAPM2nlcrnz/NBwd21NJHSAaJ7VSzGXXiAwBz5syBq6sr4uLikJqaCgcHB7Ro0QLR0dHo378/YmNj0aJFCwDArFmz8NNPP2HUqFHYsmUL6tSpg1mzZmH69OkYNmwYBg8ejHXr1pVZT9OmTbFgwQL8+9//RnR0NDp27Ii4uLhyJS3W1ta4dOkS1q9fj/v376N27doYO3YsPvzww4poCr34Lt4F38W76DsMg/bnCTm6eb2q7zCqBX6enu8N33b6DqFaYDuVKL0RoS7nGyJJ/H0CCdV4OTk5sLe3Ryh6wkziX8LPI5lb6DuEakEU8Qad2jCxMa6l0FQ5ikUhfn78DbKzsyttzmbp90SbXRNgZvPyw+nFjwtwsteSSo31ZRj15GYiIiIyLkY/1EVERESaOLmZiIiIjAZvYEhERERGo6b2+HCODxERERkN9vgQERGRBqHjUJeh9vgw8SEiIiINAoAuN7wx1HvlcKiLiIiIjAZ7fIiIiEiDEhKkGnjnZiY+REREpIGruoiIiIiqOfb4EBERkQalkCDxBoZERERkDITQcVWXgS7r4lAXERERGZzPPvsMkiQhMjJSVZafn4+xY8fC2dkZtra26NOnD27fvl2u6zLxISIiIg2lk5t12V7WqVOnsGrVKgQFBamVT5o0Cbt378a3336Lw4cP4+bNm+jdu3e5rs3Eh4iIiDToK/HJzc3FwIEDsWbNGjg6OqrKs7Oz8dVXX2HBggXo3LkzWrZsifj4eBw/fhwnTpzQ+vpMfIiIiEhD6dPZddkAICcnR20rKCh4br1jx47Fm2++ibCwMLXyxMREFBUVqZU3atQI9erVQ0JCgtbvi4kPERERVRpPT0/Y29urtri4uGceu3nzZvz+++9lHpOZmQkLCws4ODiolbu5uSEzM1PreLiqi4iIiDRU1KqujIwMyOVyVblMJivz+IyMDEycOBH79++HpaXly1f8AuzxISIiIg0liY8uc3xKriOXy9W2ZyU+iYmJuHPnDlq0aAEzMzOYmZnh8OHDWLJkCczMzODm5obCwkJkZWWpnXf79m24u7tr/b7Y40NERER616VLF5w9e1atbNiwYWjUqBGmTZsGT09PmJub4+DBg+jTpw8AIDk5Genp6QgODta6HiY+REREpKGqn9VlZ2eHJk2aqJXZ2NjA2dlZVT58+HBMnjwZTk5OkMvlGD9+PIKDg9G2bVut62HiQ0RERBrE/226nF/RFi5cCBMTE/Tp0wcFBQUIDw/H8uXLy3UNJj5ERERkkA4dOqS2b2lpiWXLlmHZsmUvfU0mPkRERKShqoe6qgoTHyIiItJkiGNdFYCJDxEREWnSsccHBtrjw/v4EBERkdFgjw8RERFpqKg7NxsaJj5ERESkgZObiYyMKCrUdwhUgygfP9Z3CNWCqd8r+g7BoEmKAiBF31FUb0x8iIiISJOQdJugzB4fIiIiqi5q6hwfruoiIiIio8EeHyIiItLEGxgSERGRsTDqVV3fffed1hd86623XjoYIiIiosqkVeLTq1cvrS4mSRIUCoUu8RAREZGhMNDhKl1olfgolcrKjoOIiIgMSE0d6tJpVVd+fn5FxUFERESGRFTAZoDKnfgoFArMmTMHderUga2tLVJTUwEAM2bMwFdffVXhARIRERFVlHInPp9++inWrVuHefPmwcLCQlXepEkTfPnllxUaHBEREemLVAGb4Sl34rNhwwasXr0aAwcOhKmpqaq8adOmuHTpUoUGR0RERHrCoa4Sf/31F3x8fDTKlUolioqKKiQoIiIiospQ7sQnICAAR48e1Sjftm0bmjdvXiFBERERkZ7V0B6fct+5OSYmBkOGDMFff/0FpVKJHTt2IDk5GRs2bMD3339fGTESERFRVauhT2cvd49Pz549sXv3bhw4cAA2NjaIiYnBxYsXsXv3bnTt2rUyYiQiIiKqEC/1rK7XXnsN+/fvr+hYiIiIyEAIUbLpcr4heumHlJ4+fRoXL14EUDLvp2XLlhUWFBEREekZn85e4saNGxgwYACOHTsGBwcHAEBWVhbatWuHzZs3o27duhUdIxEREVGFKPccnw8++ABFRUW4ePEiHjx4gAcPHuDixYtQKpX44IMPKiNGIiIiqmqlk5t12QxQuXt8Dh8+jOPHj6Nhw4aqsoYNG2Lp0qV47bXXKjQ4IiIi0g9JlGy6nG+Iyp34eHp6lnmjQoVCAQ8PjwoJioiIiPSshs7xKfdQ1+eff47x48fj9OnTqrLTp09j4sSJ+OKLLyo0OCIiIqKKpFWPj6OjIyTpf2N1jx8/Rps2bWBmVnJ6cXExzMzM8P7776NXr16VEigRERFVoRp6A0OtEp9FixZVchhERERkUGroUJdWic+QIUMqOw4iIiKiSvfSNzAEgPz8fBQWFqqVyeVynQIiIiIiA1BDe3zKPbn58ePHGDduHGrVqgUbGxs4OjqqbURERFQD1NCns5c78Zk6dSp+/vlnrFixAjKZDF9++SVmzZoFDw8PbNiwoTJiJCIiIqoQ5R7q2r17NzZs2IDQ0FAMGzYMr732Gnx8fODl5YWNGzdi4MCBlREnERERVaUauqqr3D0+Dx48QIMGDQCUzOd58OABAKBDhw44cuRIxUZHREREelF652ZdNkNU7h6fBg0a4Nq1a6hXrx4aNWqErVu3onXr1ti9e7fqoaVUMby9vREZGYnIyEh9h1JpIobewz9G34GTazFSL1hh+cd1kJxkre+wDA7bSTtsJ+2wnZ4vfvM+uLnnaZR/v7MBli9uVvUBUYUqd4/PsGHD8McffwAApk+fjmXLlsHS0hKTJk3ClClTKjzAZzl06BAkSUJWVlaV1fmyvL29eS+kMoS89RAjZ97ExgXuGBvuh9QLlvh0UyrsnTUfiWLM2E7aYTtph+30YhM/7ISBvburtn9+1AEAcPRwHT1HVsU4ubnEpEmTMGHCBABAWFgYLl26hE2bNuHMmTOYOHFihQeoq6eX25Ph6D3yHvZtcsJPW5yQfsUSS6bVRcETCeEDHug7NIPCdtIO20k7bKcXy8mW4eEDS9XWOvgWbv5lg7NJLvoOjSpAuROfp3l5eaF3794ICgoq97lKpRJxcXGoX78+rKys0LRpU2zbtg1CCISFhSE8PBxClKSMDx48QN26dRETE4O0tDR06tQJwP8epzF06FAAQGhoKMaNG4fIyEi4uLggPDwcALBgwQIEBgbCxsYGnp6eGDNmDHJzc1WxXL9+HREREXB0dISNjQ0aN26MH374AUII+Pj4aDyHLCkpCZIkISUlBUIIxMbGol69epDJZPDw8FAlh6Ghobh+/TomTZoESZLUHv2xfft2NG7cGDKZDN7e3pg/f/5z2ysrKwsffPABXF1dIZfL0blzZ1XvW3VjZq6Eb1Aefj9qpyoTQsKZo3YIaKnZxWys2E7aYTtph+1UfmZmSnTqmoGffvACYJiTdSuLBB3n+Oj7DTyDVnN8lixZovUFS7/wtREXF4evv/4aK1euhK+vL44cOYL33nsPrq6uWL9+PQIDA7FkyRJMnDgRo0aNQp06dRATEwNJkrB9+3b06dMHycnJkMvlsLKyUl13/fr1GD16NI4dO6YqMzExwZIlS1C/fn2kpqZizJgxmDp1KpYvXw4AGDt2LAoLC3HkyBHY2NjgwoULsLW1hSRJeP/99xEfH4+oqCjV9eLj49GxY0f4+Phg27ZtWLhwITZv3ozGjRsjMzNTlZDs2LEDTZs2xciRIzFixAjV+YmJiejXrx9iY2PRv39/HD9+HGPGjIGzs7MqiXta3759YWVlhb1798Le3h6rVq1Cly5dcPnyZTg5OZV5TkFBAQoKClT7OTk5Wv98KpPcSQFTMyDrrvpH8OE9M3j6FDzjLOPDdtIO20k7bKfyC+5wE7a2RTiwz0vfoVAF0SrxWbhwoVYXkyRJ68SnoKAAc+fOxYEDBxAcHAygZOL0r7/+ilWrVmHTpk1YtWoVBg8ejMzMTPzwww84c+aM6sGopV/0tWrV0phU7evri3nz5qmV/X2CsLe3Nz755BOMGjVKlfikp6ejT58+CAwMVMVSaujQoYiJicFvv/2G1q1bo6ioCJs2bVL1AqWnp8Pd3R1hYWEwNzdHvXr10Lp1a1WcpqamsLOzg7u7u+qaCxYsQJcuXTBjxgwAgJ+fHy5cuIDPP/+8zMTn119/xW+//YY7d+5AJpMBAL744gvs2rUL27Ztw8iRI8ts57i4OMyaNesZPwUiInqe17un4fRJNzy4b/Xig2uaGrqcXavE59q1axVecUpKCvLy8tC1a1e18sLCQjRv3hxASQ/Hzp078dlnn2HFihXw9fXV6totW7bUKDtw4ADi4uJw6dIl5OTkoLi4GPn5+cjLy4O1tTUmTJiA0aNH46effkJYWBj69OmjGr7z8PDAm2++ibVr16pWsBUUFKBv376qOBctWoQGDRqgW7du6N69OyIiIlRJWlkuXryInj17qpW1b98eixYtgkKhgKmpqdprf/zxB3Jzc+Hs7KxW/uTJE1y9evWZ9URHR2Py5Mmq/ZycHHh6ej7z+KqS88AUimLAwbVYrdzRpRgP7+r0JJUahe2kHbaTdthO5VPLLQ/NWt7BpzFt9R2KfvCRFRWrdH7Nnj17kJSUpNouXLiAbdu2AQDy8vKQmJgIU1NTXLlyRetr29jYqO2npaWhR48eCAoKwvbt25GYmIhly5YB+N/k5w8++ACpqakYNGgQzp49i1atWmHp0qWqa3zwwQfYvHkznjx5gvj4ePTv3x/W1iXLPz09PZGcnIzly5fDysoKY8aMQceOHVFUVHGrJHJzc1G7dm21tkpKSkJycvJzV9PJZDLI5XK1zRAUF5ngyp/WaN7hkapMkgSadcjFhUQuqy3FdtIO20k7bKfy6fpGGrKzZPjthPuLD6ZqQ28pfkBAAGQyGdLT0xESElLmMR999BFMTEywd+9edO/eHW+++SY6d+4MALCwsAAAKBSKF9aVmJgIpVKJ+fPnw8SkJNfbunWrxnGenp4YNWoURo0ahejoaKxZswbjx48HAHTv3h02NjZYsWIF9u3bp3GzRisrK0RERCAiIgJjx45Fo0aNcPbsWbRo0QIWFhYacfr7+6vNQQKAY8eOwc/PT6O3BwBatGiBzMxMmJmZwdvb+4XvuTrYsdoFUYsycPkPaySfscbbI+7C0lqJnzaXPV/JWLGdtMN20g7bSTuSJNC123Uc+NELSoXe+gj0q4b2+Ogt8bGzs0NUVBQmTZoEpVKJDh06IDs7G8eOHYNcLoeLiwvWrl2LhIQEtGjRAlOmTMGQIUPw559/wtHREV5eXpAkCd9//z26d+8OKysr2NrallmXj48PioqKsHTpUkRERODYsWNYuXKl2jGRkZF444034Ofnh4cPH+KXX36Bv7+/6nVTU1MMHToU0dHR8PX1Vc1LAoB169ZBoVCgTZs2sLa2xtdffw0rKyt4eZVMhvP29saRI0fwzjvvQCaTwcXFBR999BFeffVVzJkzB/3790dCQgL+85//qOYcPS0sLAzBwcHo1asX5s2bBz8/P9y8eRN79uzB22+/jVatWun6I6lyh79zhL2zAoOnZMLRtRip563wr4H1kXXPXN+hGRS2k3bYTtphO2mnWcs7qOX+BPt/MN5JzbrefdlQ79ys1zR2zpw5mDFjBuLi4uDv749u3bphz5498Pb2xvDhwxEbG4sWLVoAAGbNmgU3NzeMGjUKAFCnTh3MmjUL06dPh5ubG8aNG/fMepo2bYoFCxbg3//+N5o0aYKNGzciLi5O7RiFQoGxY8eq4vDz89NIQoYPH47CwkIMGzZMrdzBwQFr1qxB+/btERQUhAMHDmD37t2q+TizZ89GWloaXnnlFbi6ugIo6cHZunUrNm/ejCZNmiAmJgazZ89+5oouSZLwww8/oGPHjhg2bBj8/Pzwzjvv4Pr163Bzc9O+0Q3Md/EuGNw6ABH1gzCxhy+Sz9i8+CQjxHbSDttJO2ynFztz2g3dQ3vjrxt2Lz6YKsSKFSsQFBSkmpYRHByMvXv3ql7Pz8/H2LFj4ezsDFtbW/Tp0we3b98udz2SKL1RDr3Q0aNH0aVLF2RkZFTbZCMnJwf29vYIRU+YSfwLj4gMi6nfK/oOwaAVKwpwMGURsrOzK23OZun3hPcnn8LE0vKlr6PMz0fax//SOtbdu3fD1NQUvr6+EEJg/fr1+Pzzz3HmzBk0btwYo0ePxp49e7Bu3TrY29tj3LhxMDEx0Zg28iIv1eNz9OhRvPfeewgODsZff/0FAPjvf/+LX3/99WUuZ/AKCgpw48YNxMbGom/fvtU26SEiItJaFT+yIiIiAt27d4evry/8/Pzw6aefwtbWFidOnEB2dja++uorLFiwAJ07d0bLli0RHx+P48eP48SJE+Wqp9yJz/bt2xEeHg4rKyucOXNGdXO87OxszJ07t7yXqxa++eYbeHl5ISsrS+P+QERERPRsOTk5atvfb6r7LAqFAps3b8bjx48RHByMxMREFBUVISwsTHVMo0aNUK9ePSQkJJQrnnInPp988glWrlyJNWvWwNz8f0Ml7du3x++//17ey1ULQ4cOhUKhQGJiIurUMbKH1BERkVHS6XEVf5sY7enpCXt7e9X29Bzbvzt79ixsbW0hk8kwatQo7Ny5EwEBAcjMzISFhYXGDYvd3NyQmZlZrvdV7lVdycnJ6Nixo0a5vb19tXhSOhEREWmhgu7cnJGRoTbHp/TpA2Vp2LAhkpKSkJ2djW3btmHIkCE4fPjwy8dQhnInPu7u7khJSdG4l8yvv/6q9pgHIiIiqsYq6D4+5bl5roWFBXx8fACUPIXh1KlTWLx4Mfr374/CwkJkZWWp9frcvn1b7XFQ2ij3UNeIESMwceJEnDx5EpIk4ebNm9i4cSOioqIwevTo8l6OiIiIqExKpRIFBQVo2bIlzM3NcfDgQdVrycnJSE9PV7uvnjbK3eMzffp0KJVKdOnSBXl5eejYsSNkMhmioqJUdzkmIiKi6q2qb2AYHR2NN954A/Xq1cOjR4+wadMmHDp0CD/++CPs7e0xfPhwTJ48GU5OTpDL5Rg/fjyCg4PRtm35nqVW7sRHkiT861//wpQpU5CSkoLc3FwEBAQ8867JREREVA1V8SMr7ty5g8GDB+PWrVuwt7dHUFAQfvzxR9XDzBcuXAgTExP06dMHBQUFCA8Pf+bTDp7npR9ZYWFhgYCAgJc9nYiIiEjlq6++eu7rlpaWWLZsmeoh4y+r3IlPp06dIEnPnuX9888/6xQQERERGQAdh7pqzENKmzVrprZfVFSEpKQknDt3DkOGDKmouIiIiEif+HT2EgsXLiyzPDY2Frm5uToHRERERFRZKuzp7O+99x7Wrl1bUZcjIiIifariZ3VVlZee3Py0hIQEWOrwFFciIiIyHFW9nL2qlDvx6d27t9q+EAK3bt3C6dOnMWPGjAoLjIiIiKiilTvxsbe3V9s3MTFBw4YNMXv2bLz++usVFhgRERFRRStX4qNQKDBs2DAEBgbC0dGxsmIiIiIifauhq7rKNbnZ1NQUr7/+Op/CTkREVMOVzvHRZTNE5V7V1aRJE6SmplZGLERERESVqtyJzyeffIKoqCh8//33uHXrFnJyctQ2IiIiqiFq2FJ2oBxzfGbPno2PPvoI3bt3BwC89dZbao+uEEJAkiQoFIqKj5KIiIiqVg2d46N14jNr1iyMGjUKv/zyS2XGQ0RERFRptE58hChJ3UJCQiotGCIiIjIMvIEh8NynshMREVENYuxDXQDg5+f3wuTnwYMHOgVEREREVFnKlfjMmjVL487NREREVPNwqAvAO++8g1q1alVWLERERGQoauhQl9b38eH8HiIiIqruyr2qi4iIiIxADe3x0TrxUSqVlRkHERERGRDO8SEiopdW2O1VfYdQLSjNOK3ieYqL8oGUKqqshvb4lPtZXURERETVFXt8iIiISFMN7fFh4kNEREQaauocHw51ERERkdFgjw8RERFp4lAXERERGQsOdRERERFVc+zxISIiIk0c6iIiIiKjUUMTHw51ERERkdFgjw8RERFpkP5v0+V8Q8TEh4iIiDTV0KEuJj5ERESkgcvZiYiIiKo59vgQERGRJg51ERERkVEx0ORFFxzqIiIiIqPBHh8iIiLSUFMnNzPxISIiIk01dI4Ph7qIiIjIaLDHh4iIiDRwqIuIiIiMB4e6iIiIiKo39vgQERGRBg51ERERkfGooUNdTHyIiIhIUw1NfDjHh4iIiPQuLi4Or776Kuzs7FCrVi306tULycnJasfk5+dj7NixcHZ2hq2tLfr06YPbt2+Xqx4mPkRERKShdI6PLlt5HD58GGPHjsWJEyewf/9+FBUV4fXXX8fjx49Vx0yaNAm7d+/Gt99+i8OHD+PmzZvo3bt3uerhUBcRERFpqqChrpycHLVimUwGmUymcfi+ffvU9tetW4datWohMTERHTt2RHZ2Nr766its2rQJnTt3BgDEx8fD398fJ06cQNu2bbUKiz0+REREVGk8PT1hb2+v2uLi4rQ6Lzs7GwDg5OQEAEhMTERRURHCwsJUxzRq1Aj16tVDQkKC1vGwx4eIiIg0SEJAEi/f5VN6bkZGBuRyuaq8rN6epymVSkRGRqJ9+/Zo0qQJACAzMxMWFhZwcHBQO9bNzQ2ZmZlax8XEh/QqYug9/GP0HTi5FiP1ghWWf1wHyUnW+g7L4LCdtMN2Uhfkdwv9u/0JP+/7cHHIw8dLw3DsjHeZx04a9Cve6nQJ//mmLbbvb1K1gepZkO8tDHj9T/h53YOLQx7+tbwrfk3yVr0+feghvNHuito5J8/VxdQlb1RxpFWsgoa65HK5WuKjjbFjx+LcuXP49ddfdQigbBzqIr0JeeshRs68iY0L3DE23A+pFyzx6aZU2DsX6Ts0g8J20g7bSZOlrBhXM5yx+Ot2zz2uQ4s0BLxyB3cfGmeSaCUrRsoNJyza9Ox2OnmuLt6OGqjaZn/ZuQojNC7jxo3D999/j19++QV169ZVlbu7u6OwsBBZWVlqx9++fRvu7u5aX5+JTyUoLCys0fVVlN4j72HfJif8tMUJ6VcssWRaXRQ8kRA+4IG+QzMobCftsJ00/XbWE2t3tsKvv3s/8xgXh8eY8O5xfLq6ExQK4/xKOHnOE1/9v1dxNKn+M48pLDbFgxxr1Zab9+Lhmuquqld1CSEwbtw47Ny5Ez///DPq11f/ebRs2RLm5uY4ePCgqiw5ORnp6ekIDg7Wuh6j+5SHhoZi/PjxiIyMhKOjI9zc3LBmzRo8fvwYw4YNg52dHXx8fLB3714AJbPKnx5P3LVrFyRJUu3HxsaiWbNm+PLLL1G/fn1YWloCACRJwqpVq9CjRw9YW1vD398fCQkJSElJQWhoKGxsbNCuXTtcvXpVda2hQ4eiV69eavVFRkYiNDRU7T2MGzcOkZGRcHFxQXh4eMU2UhUwM1fCNygPvx+1U5UJIeHMUTsEtMzTY2SGhe2kHbbTy5EkgegRh7BlXxDSbjrqOxyD1szvFnZ98V/8d/ZWTH73V8ht8vUdUuUTFbCVw9ixY/H1119j06ZNsLOzQ2ZmJjIzM/HkyRMAgL29PYYPH47Jkyfjl19+QWJiIoYNG4bg4GCtV3QBRpj4AMD69evh4uKC3377DePHj8fo0aPRt29ftGvXDr///jtef/11DBo0CHl52v/CTElJwfbt27Fjxw4kJSWpyufMmYPBgwcjKSkJjRo1wrvvvosPP/wQ0dHROH36tCrDfZn3YGFhgWPHjmHlypXPPK6goAA5OTlqmyGQOylgagZk3VWfZvbwnhkcXYv1FJXhYTtph+30cga88QcUChNsP9BY36EYtN/Oe2JufCgmL3wTq3a0RlO/W5g3YR9MJKW+Q6tRVqxYgezsbISGhqJ27dqqbcuWLapjFi5ciB49eqBPnz7o2LEj3N3dsWPHjnLVY5STm5s2bYqPP/4YABAdHY3PPvsMLi4uGDFiBAAgJiYGK1aswJ9//qn1NQsLC7Fhwwa4urqqlQ8bNgz9+vUDAEybNg3BwcGYMWOGqpdm4sSJGDZsWLnfg6+vL+bNm/fC4+Li4jBr1qxyX5+IajY/r3vo0/U8Rs7qBUB60eFG7edTr6j+nfqXE67ecMLmuVvQrOEt/H6pjh4jq1xV/ZBSocUKMktLSyxbtgzLli17yaiMtMcnKChI9W9TU1M4OzsjMDBQVebm5gYAuHPnjtbX9PLy0kh6nq6r9LpP15Wfn1/unpiWLVtqdVx0dDSys7NVW0ZGRrnqqSw5D0yhKAYcnvpr3NGlGA/vGmU+Xia2k3bYTuUX6JcJB7sn2PL5ZhxY8xUOrPkK7i65GN3/JL6Zt1nf4Rm0W/fkyHpkiTq1DKMHvdJU8VBXVTHK3wjm5uZq+5IkqZWVzt9RKpUwMTHRyEKLijRXidjY2LywrtLrPqsuADrX97Rn3SFT34qLTHDlT2s07/AICfvsAZTMN2jWIRffrXPWc3SGg+2kHbZT+e0/7oPECx5qZfMm78P+BB/s+9VPT1FVD64OuZDb5ON+ds1eBVfVPT5VxSgTn/JwdXXFo0eP8PjxY1Wy8fc5PJVR37lz59TKkpKSNJK1mmDHahdELcrA5T+skXzGGm+PuAtLayV+2uyk79AMCttJO2wnTZayIrVeidouj/CK5308eizDnQe2yHlsqXa8QmGCB9nWyMh0qOJI9ctKVoQ6rurt5FP3PnLyZHj0WIYhPX7Hkd+98SDHGh6uORjV5zf8dVeOU+frPueqZKiY+LxAmzZtYG1tjX/+85+YMGECTp48iXXr1lVafZ07d8bnn3+ODRs2IDg4GF9//TXOnTuH5s2bV1qd+nL4O0fYOysweEomHF2LkXreCv8aWB9Z92pekqcLtpN22E6aGnrfxaJpP6j2xw44CQDY96sv/r02RF9hGZyGXnexOGqPan9cvxMAgL3HfbFgYwe8Uvc+ugVfhq11Ie5lWeP0hbr46v+1RFGxqb5CrhoVdANDQ8PE5wWcnJzw9ddfY8qUKVizZg26dOmC2NhYjBw5slLqCw8Px4wZMzB16lTk5+fj/fffx+DBg3H27NlKqU/fvot3wXfxLvoOw+CxnbTDdlL3R7IHOr3/gdbHD5j6TiVGY7iSLnsgZOSIZ74+ZXH3KozGsBjqcJUuJKHNNGqqMXJycmBvb49Q9ISZZLx/CRNVtcJur+o7hGpBacYVZs9TXJSPE/tikJ2dXe7HQGir9HuiZb9PYWZu+eITnqG4KB+JW/9VqbG+DPb4EBERkSYhSjZdzjdATHyIiIhIQ01d1WWU9/EhIiIi48QeHyIiItLEVV1ERERkLCRlyabL+YaIQ11ERERkNNjjQ0RERJo41EVERETGoqau6mLiQ0RERJpq6H18OMeHiIiIjAZ7fIiIiEgDh7qIiIjIeNTQyc0c6iIiIiKjwR4fIiIi0sChLiIiIjIeXNVFREREVL2xx4eIiIg0cKiLiIiIjAdXdRERERFVb+zxISIiIg0c6iIiIiLjoRQlmy7nGyAmPkRERKSJc3yIiIiIqjf2+BAREZEGCTrO8amwSCoWEx8iIiLSxDs3ExEREVVv7PEhIiIiDVzOTkRERMaDq7qIiIiIqjf2+BAREZEGSQhIOkxQ1uXcysTEx0hJ5haQJHN9h2HQRFGhvkOgGsTy6AV9h1At7L1yTN8hGLScR0o4+lVRZcr/23Q53wBxqIuIiIiMBnt8iIiISAOHuoiIiMh41NBVXUx8iIiISBPv3ExERERUvbHHh4iIiDTwzs1ERERkPDjURURERFS9sceHiIiINEjKkk2X8w0REx8iIiLSxKEuIiIiospz5MgRREREwMPDA5IkYdeuXWqvCyEQExOD2rVrw8rKCmFhYbhy5Uq56mDiQ0RERJpEBWzl9PjxYzRt2hTLli0r8/V58+ZhyZIlWLlyJU6ePAkbGxuEh4cjPz9f6zo41EVEREQa9PHIijfeeANvvPFGma8JIbBo0SJ8/PHH6NmzJwBgw4YNcHNzw65du/DOO+9oVQd7fIiIiKjS5OTkqG0FBQUvdZ1r164hMzMTYWFhqjJ7e3u0adMGCQkJWl+HiQ8RERFpKp3crMsGwNPTE/b29qotLi7upcLJzMwEALi5uamVu7m5qV7TBoe6iIiISJMAoMuS9P8b6crIyIBcLlcVy2QyncLSFXt8iIiISEPpHB9dNgCQy+Vq28smPu7u7gCA27dvq5Xfvn1b9Zo2mPgQERGRwatfvz7c3d1x8OBBVVlOTg5OnjyJ4OBgra/DoS4iIiLSJKDjDQzLf0pubi5SUlJU+9euXUNSUhKcnJxQr149REZG4pNPPoGvry/q16+PGTNmwMPDA7169dK6DiY+REREpEkPd24+ffo0OnXqpNqfPHkyAGDIkCFYt24dpk6disePH2PkyJHIyspChw4dsG/fPlhaWmpdBxMfIiIiMgihoaEQz0mYJEnC7NmzMXv27Jeug4kPERERaVICkHQ83wAx8SEiIiIN+rhzc1Xgqi4iIiIyGuzxISIiIk16mNxcFZj4EBERkaYamvhwqIuIiIiMBnt8iIiISFMN7fFh4kNERESauJydiIiIjAWXsxMRERFVc+zxqca8vb0RGRmJyMhIfYfyUpq0foR/fHgLvoF5cHYrwqwRPkj4yVHfYRmkiKH38I/Rd+DkWozUC1ZY/nEdJCdZ6zssg8N2er5+H95A+9fvo26DJygsMMGF3+VY+7kX/rpmpe/Q9OreLXN89WltnPpFjoInJvDwLsBHC9Ph1/QJAOC/X7jj0P9zwN2b5jC3EPAJfIJh02+hUYs8PUdeyWroHB/2+JDeWForcO2iNZbN8NJ3KAYt5K2HGDnzJjYucMfYcD+kXrDEp5tSYe9cpO/QDArb6cUCW+dg98bamNQ3CP8c2hhm5kp8Gn8eMiuFvkPTm0dZppjc0xemZgKffJ2KNYcuYWTMTdja/69N6jTIx9hPb2DVz8mYvysF7p6FiB7wCrLum+ox8iqgFLpvBog9PpWosLAQFhYW+g7DYJ0+5IDThxz0HYbB6z3yHvZtcsJPW5wAAEum1UXrLjkIH/AAW//jpufoDAfb6cVmDA9Q218wzRebT56Cb5NcnDtlr6eo9Gvrslpw8ShE1KIMVZl7vUK1Yzr3zlLbHxn7F/Z944xrF6zQ/LXcqgiTKhB7fP4mNDQUEyZMwNSpU+Hk5AR3d3fExsaqXk9PT0fPnj1ha2sLuVyOfv364fbt26rXY2Nj0axZM3z55ZeoX78+LC0tAZQ8TXbVqlXo0aMHrK2t4e/vj4SEBKSkpCA0NBQ2NjZo164drl69qrrW1atX0bNnT7i5ucHW1havvvoqDhw4UGVtQYbBzFwJ36A8/H7UTlUmhIQzR+0Q0LKGd7OXA9vp5VjbFgMAHmUZ79/AJ36yh1/TPHwy0hv9AhtjTFc//LDR6ZnHFxVK+OFrZ9jIFWgQ8KQKI9WD0qEuXTYDxMTnKevXr4eNjQ1OnjyJefPmYfbs2di/fz+USiV69uyJBw8e4PDhw9i/fz9SU1PRv39/tfNTUlKwfft27NixA0lJSaryOXPmYPDgwUhKSkKjRo3w7rvv4sMPP0R0dDROnz4NIQTGjRunOj43Nxfdu3fHwYMHcebMGXTr1g0RERFIT08v1/spKChATk6O2kbVh9xJAVMzIOuu+hfTw3tmcHQt1lNUhoftVH6SJPDhx2k4f9oO16/Y6DscvbmVboHvN7jAo34B5m5KRY8h97FiRl3s36o+3/DEfjl6+gQion4Qdq5xRdzmFNg71/QhQl2THsNMfIw3zX+GoKAgzJw5EwDg6+uL//znPzh48CAA4OzZs7h27Ro8PT0BABs2bEDjxo1x6tQpvPrqqwBKhrc2bNgAV1dXtesOGzYM/fr1AwBMmzYNwcHBmDFjBsLDwwEAEydOxLBhw1THN23aFE2bNlXtz5kzBzt37sR3332nliC9SFxcHGbNmlXeZiCiGm5sbCq8ffMQNaCJvkPRK6EEfIOe4P3oWwAAn8AnSLtkiT3/dUHXfg9VxzVrn4vl+5OR88AMezc649MPvbFkzxU4uDCxrm7Y4/OUoKAgtf3atWvjzp07uHjxIjw9PVVJDwAEBATAwcEBFy9eVJV5eXlpJD1PX9fNrWS+QWBgoFpZfn6+qkcmNzcXUVFR8Pf3h4ODA2xtbXHx4sVy9/hER0cjOztbtWVkZLz4JDIYOQ9MoSgGHJ7qtXB0KcbDu/y7pRTbqXxGx6SidaeHmDaoMe5lyvQdjl451SqGl1++Wpmnbz7u/GWuVmZprUSd+oXwb5mHyQsyYGoG7Pvm2UNiNQKHuoyDubn6h12SJCiV2t9+0sam7C7jv19XkqRnlpXWFRUVhZ07d2Lu3Lk4evQokpKSEBgYiMJC9Ul3LyKTySCXy9U2qj6Ki0xw5U9rNO/wSFUmSQLNOuTiQiKXaZdiO2lLYHRMKtp1fYDpgxrj9g1LfQekdwGvPkbGVfXk769UGWrVef5qQKEEigpq+FcoV3UZN39/f2RkZCAjI0PV63PhwgVkZWUhICDgBWeX37FjxzB06FC8/fbbAEp6gNLS0iq8Hn2ytFbAw7tAte/uWYAGAXl4lGWKuzeN+6/Qv9ux2gVRizJw+Q9rJJ+xxtsj7sLSWomfNtfwvzbLie30YmNjUxEacQ+zRzfCk8emcHQp+UPq8SNTFBbU8KXZz9B75B1MessP3yyphY4RWUg+Y40fvnZG5Oc3AAD5eSbYtNgNwa9nw8mtCDkPzPBdvAvuZZrjtYgs/QZPL4WJj5bCwsIQGBiIgQMHYtGiRSguLsaYMWMQEhKCVq1aVXh9vr6+2LFjByIiIiBJEmbMmFGunqfqwC/oMeZtSVbtfxhTMgy3/1tnzI9qoK+wDM7h7xxh76zA4CmZcHQtRup5K/xrYH1k3TN/8clGhO30Yj0GlqxCnbfxvFr5/Gk+OLCjlj5C0ruGzZ4g5qtriI+rjY0L3eHuWYhRs/9C594l83tMTARupMgw51tv5Dwwg52jAn5N8zB/5xV4N8x/wdWrOaEs2XQ53wAx8dGSJEn4f//v/2H8+PHo2LEjTExM0K1bNyxdurRS6luwYAHef/99tGvXDi4uLpg2bVqNW5H15wk5unm9qu8wqoXv4l3wXbyLvsMweGyn53vDt52+QzBIbbvmoG3Xsn+/WlgKxHyVVrUBGYoaeudmSQgDjYwqRU5ODuzt7dHJvC/MJP4l/DyiqHzzqYiex+QZ8/9I3d4rx/QdgkHLeaSEo18qsrOzK23OZun3RFidUTAzeflpB8XKAhz4a2WlxvoyavjMLCIiIqL/4VAXERERaaqhQ11MfIiIiEiTgI6JT4VFUqE41EVERERGgz0+REREpIlDXURERGQ0lEoAOtyLx0DvPcehLiIiIjIa7PEhIiIiTRzqIiIiIqNRQxMfDnURERGR0WCPDxEREWlSCuh0Mx6lYfb4MPEhIiIiDUIoIXR4wrou51YmJj5ERESkSQjdem04x4eIiIhIv9jjQ0RERJqEjnN8DLTHh4kPERERaVIqAUmHeToGOseHQ11ERERkNNjjQ0RERJo41EVERETGQiiVEDoMdRnqcnYOdREREZHRYI8PERERaeJQFxERERkNpQCkmpf4cKiLiIiIjAZ7fIiIiEiTEAB0uY+PYfb4MPEhIiIiDUIpIHQY6hJMfIiIiKjaEEro1uPD5exEREREz7Vs2TJ4e3vD0tISbdq0wW+//Vah12fiQ0RERBqEUui8ldeWLVswefJkzJw5E7///juaNm2K8PBw3Llzp8LeFxMfIiIi0iSUum/ltGDBAowYMQLDhg1DQEAAVq5cCWtra6xdu7bC3hbn+BiZ0slmxaJIz5EYPsE2ogpkIgr1HUK1kPPIMOeFGIqc3JL2qYqJw8Uo0un+hcUo+R2ak5OjVi6TySCTyTSOLywsRGJiIqKjo1VlJiYmCAsLQ0JCwssH8hQmPkbm0aNHAICjxbv0GwiRsXms7wCqB0c/fUdQPTx69Aj29vaVcm0LCwu4u7vj18wfdL6Wra0tPD091cpmzpyJ2NhYjWPv3bsHhUIBNzc3tXI3NzdcunRJ51hKMfExMh4eHsjIyICdnR0kSdJ3OMjJyYGnpycyMjIgl8v1HY7BYjtph+2kHbaTdgyxnYQQePToETw8PCqtDktLS1y7dg2Fhbr3UgohNL5ryurtqUpMfIyMiYkJ6tatq+8wNMjlcoP5xWLI2E7aYTtph+2kHUNrp8rq6fk7S0tLWFpaVno9f+fi4gJTU1Pcvn1brfz27dtwd3evsHo4uZmIiIj0zsLCAi1btsTBgwdVZUqlEgcPHkRwcHCF1cMeHyIiIjIIkydPxpAhQ9CqVSu0bt0aixYtwuPHjzFs2LAKq4OJD+mVTCbDzJkz9T7ma+jYTtphO2mH7aQdtlPV69+/P+7evYuYmBhkZmaiWbNm2Ldvn8aEZ11IwlAfpkFERERUwTjHh4iIiIwGEx8iIiIyGkx8iIiIyGgw8aEq5+3tjUWLFqn2MzMz0bVrV9jY2MDBwUFvcdUk69atY1vqwdOfbaKy8HOiX0x8qNI868v31KlTGDlypGp/4cKFuHXrFpKSknD58uUKqTs0NBSRkZEVcq2qcOjQIUiShKysLH2HUmmq03vkFxNRzcXl7FQpioqe/YBPV1dXtf2rV6+iZcuW8PX1reywqr3CwkJYWFjoO4xKZQzvUd+quo2r28+0usVL5cMeH9LKvn370KFDBzg4OMDZ2Rk9evTA1atXAQBpaWmQJAlbtmxBSEgILC0tsXHjRgwbNgzZ2dmQJAmSJKkeSvf3v6a9vb2xfft2bNiwAZIkYejQoQCABQsWIDAwEDY2NvD09MSYMWOQm5urFtOxY8cQGhoKa2trODo6Ijw8HA8fPsTQoUNx+PBhLF68WFV3WlpapbeRUqlEXFwc6tevDysrKzRt2hTbtm2DEAJhYWEIDw9XPVH5wYMHqFu3LmJiYpCWloZOnToBABwdHdXaITQ0FOPGjUNkZCRcXFwQHh6udfsAwI8//gh/f3/Y2tqiW7duuHXrluq1Q4cOoXXr1qohxvbt2+P69evV5j1ev34dERERcHR0hI2NDRo3bowffvgBQgj4+Pjgiy++UIs9KSkJkiQhJSUFQgjExsaiXr16kMlk8PDwwIQJE1TxXL9+HZMmTVJ9fkpt374djRs3hkwmg7e3N+bPn//c9srKysIHH3wAV1dXyOVydO7cGX/88cdzzwkNDcX48eMRGRkJR0dHuLm5Yc2aNaqbuNnZ2cHHxwd79+4FUHbP6q5du9Tijo2NRbNmzfDll1+ifv36qkcRSJKEVatWoUePHrC2toa/vz8SEhKQkpKC0NBQ2NjYoF27dqr/6wAwdOhQ9OrVS62+yMhIhIaGqr2Hsn6mlSU0NBQTJkzA1KlT4eTkBHd3d7WHYKanp6Nnz56wtbWFXC5Hv3791B6LUJHtc/XqVfTs2RNubm6wtbXFq6++igMHDlTq+6dyEkRa2LZtm9i+fbu4cuWKOHPmjIiIiBCBgYFCoVCIa9euCQDC29tbbN++XaSmpoq0tDSxaNEiIZfLxa1bt8StW7fEo0ePhBBCeHl5iYULFwohhLhz547o1q2b6Nevn7h165bIysoSQgixcOFC8fPPP4tr166JgwcPioYNG4rRo0er4jlz5oyQyWRi9OjRIikpSZw7d04sXbpU3L17V2RlZYng4GAxYsQIVd3FxcWV3kaffPKJaNSokdi3b5+4evWqiI+PFzKZTBw6dEjcuHFDODo6ikWLFgkhhOjbt69o3bq1KCoqEsXFxWL79u0CgEhOTlZrh5CQEGFrayumTJkiLl26JC5duqRV+8THxwtzc3MRFhYmTp06JRITE4W/v7949913hRBCFBUVCXt7exEVFSVSUlLEhQsXxLp168T169erzXt88803RdeuXcWff/4prl69Knbv3i0OHz4shBDi008/FQEBAWqxT5gwQXTs2FEIIcS3334r5HK5+OGHH8T169fFyZMnxerVq4UQQty/f1/UrVtXzJ49W/X5EUKI06dPCxMTEzF79myRnJws4uPjhZWVlYiPj1fV8ffPthBChIWFiYiICHHq1Clx+fJl8dFHHwlnZ2dx//79Z7ZxSEiIsLOzE3PmzBGXL18Wc+bMEaampuKNN94Qq1evFpcvXxajR48Wzs7O4vHjxyI+Pl7Y29urXWPnzp3i77/eZ86cKWxsbES3bt3E77//Lv744w8hhBAARJ06dcSWLVtEcnKy6NWrl/D29hadO3cW+/btExcuXBBt27YV3bp1U11ryJAhomfPnmr1TZw4UYSEhKi9h7J+ppUlJCREyOVyERsbKy5fvizWr18vJEkSP/30k1AoFKJZs2aiQ4cO4vTp0+LEiROiZcuWavFWZPskJSWJlStXirNnz4rLly+Ljz/+WFhaWqr933r6c0JVi4kPvZS7d+8KAOLs2bOqxKf0C69UWb+QhdD8T9+zZ08xZMiQ59b37bffCmdnZ9X+gAEDRPv27Z95fEhIiJg4caI2b6VC5OfnC2tra3H8+HG18uHDh4sBAwYIIYTYunWrsLS0FNOnTxc2Njbi8uXLquN++eUXAUA8fPhQ7fyQkBDRvHnzF9b/dPvEx8cLACIlJUVVtmzZMuHm5iaEKPlyByAOHTpUbd9jYGCgiI2NLfPYv/76S5iamoqTJ08KIYQoLCwULi4uYt26dUIIIebPny/8/PxEYWFhmeeX9cX07rvviq5du6qVTZkyRS3B+vt5R48eFXK5XOTn56ud88orr4hVq1Y9832GhISIDh06qPaLi4uFjY2NGDRokKrs1q1bAoBISEjQOvExNzcXd+7cUTsOgPj4449V+wkJCQKA+Oqrr1Rl33zzjbC0tFTta5v4aPMzrShPt5kQQrz66qti2rRp4qeffhKmpqYiPT1d9dr58+cFAPHbb78JISq2fcrSuHFjsXTpUtU+Ex/94lAXaeXKlSsYMGAAGjRoALlcDm9vbwAlXcilWrVqVWH1HThwAF26dEGdOnVgZ2eHQYMG4f79+8jLywNQMmzRpUuXCqtPVykpKcjLy0PXrl1ha2ur2jZs2KDqBu/bty/efvttfPbZZ/jiiy+0ntPUsmVLjbIXtQ8AWFtb45VXXlHt165dG3fu3AEAODk5YejQoQgPD0dERAQWL16sNgxWHd7jhAkT8Mknn6B9+/aYOXMm/vzzT9W5Hh4eePPNN7F27VoAwO7du1FQUIC+ffuq4nzy5AkaNGiAESNGYOfOnSguLn5ujBcvXkT79u3Vytq3b48rV65AoVBoHP/HH38gNzcXzs7Oau117do1taGRsgQFBan+bWpqCmdnZwQGBqrKSm/fX/rz1IaXl5fG/Lqn6yq97tN15efnIycnR+u6gLJ/ppXp7+8D+N/n/eLFi/D09ISnp6fqtYCAADg4OODixYuqsopqn9zcXERFRcHf3x8ODg6wtbXFxYsX1X5Xkn4x8SGtRERE4MGDB1izZg1OnjyJkydPAiiZBFjKxsamQupKS0tDjx49EBQUhO3btyMxMRHLli1Tq8/KyqpC6qoopXNP9uzZg6SkJNV24cIFbNu2DQCQl5eHxMREmJqa4sqVK1pf++l21aZ9AMDc3FztPEmSVPNvACA+Ph4JCQlo164dtmzZAj8/P5w4caLavMcPPvgAqampGDRoEM6ePYtWrVph6dKlqmt88MEH2Lx5M548eYL4+Hj0798f1tbWAABPT08kJydj+fLlsLKywpgxY9CxY8fnTsovr9zcXNSuXVutrZKSkpCcnIwpU6Y899yyfnZ/Lyudv6NUKmFiYqL2cwXKXlzwrP+fZV33WXUB0Lm+ylJWm5XGrI2Kap+oqCjs3LkTc+fOxdGjR5GUlITAwEC1/5ukX1zVRS90//59JCcnY82aNXjttdcAAL/++usLz7OwsCjzL+EXSUxMhFKpxPz582FiUpKbb926Ve2YoKAgHDx4ELNmzarQul9WQEAAZDIZ0tPTERISUuYxH330EUxMTLB37150794db775Jjp37qyKF4BWMWvTPtpq3rw5mjdvjujoaAQHB2PTpk1o27Ztmcca4nv09PTEqFGjMGrUKERHR2PNmjUYP348AKB79+6wsbHBihUrsG/fPhw5ckTtXCsrK0RERCAiIgJjx45Fo0aNcPbsWbRo0aLMz4+/vz+OHTumVnbs2DH4+fnB1NRUI7YWLVogMzMTZmZmqh7SyuDq6opHjx7h8ePHqi/vpKSkSq3v3LlzamVJSUkaiYeh8Pf3R0ZGBjIyMlS9PhcuXEBWVhYCAgIqvL5jx45h6NChePvttwGUJMBVsbiCtMfEh17I0dERzs7OWL16NWrXro309HRMnz79hed5e3sjNzcXBw8eRNOmTWFtba36i/t5fHx8UFRUhKVLlyIiIgLHjh3DypUr1Y6Jjo5GYGAgxowZg1GjRsHCwgK//PIL+vbtCxcXF3h7e+PkyZNIS0uDra0tnJycVF+glcHOzg5RUVGYNGkSlEolOnTogOzsbBw7dgxyuRwuLi5Yu3YtEhIS0KJFC0yZMgVDhgzBn3/+CUdHR3h5eUGSJHz//ffo3r07rKysYGtr+9Lt8yLXrl3D6tWr8dZbb8HDwwPJycm4cuUKBg8eXG3eY2RkJN544w34+fnh4cOH+OWXX+Dv76963dTUFEOHDkV0dDR8fX0RHBysem3dunVQKBRo06YNrK2t8fXXX8PKygpeXl4ASj67R44cwTvvvAOZTAYXFxd89NFHePXVVzFnzhz0798fCQkJ+M9//oPly5eX+R7CwsIQHByMXr16Yd68efDz88PNmzexZ88evP322xU2NFz6Hv75z39iwoQJOHnyJNatW1ch1y5L586d8fnnn2PDhg0IDg7G119/jXPnzqF58+aVVqcuwsLCEBgYiIEDB2LRokUoLi7GmDFjEBISUqHD86V8fX2xY8cOREREQJIkzJgxo1w9T1QF9DzHiKqJ/fv3C39/fyGTyURQUJA4dOiQACB27typmtx85swZjfNGjRolnJ2dBQAxc+ZMIYR2k5sXLFggateuLaysrER4eLjYsGGDxsTYQ4cOiXbt2gmZTCYcHBxEeHi46vXk5GTRtm1bYWVlJQCIa9euVWh7lEWpVIpFixaJhg0bCnNzc+Hq6irCw8PFoUOHhJubm5g7d67q2MLCQtGyZUvRr18/Vdns2bOFu7u7kCRJ1R7PmqT9ovZ50YTXzMxM0atXL1G7dm1hYWEhvLy8RExMjFAoFNXmPY4bN0688sorQiaTCVdXVzFo0CBx7949tWtcvXpVABDz5s3TaIs2bdoIuVwubGxsRNu2bcWBAwdUryckJIigoCAhk8nUJglv27ZNBAQECHNzc1GvXj3x+eefq1336c92Tk6OGD9+vPDw8BDm5ubC09NTDBw4UG2i7dPKao+yJsOW/v8rfT8+Pj7CyspK9OjRQ6xevVpjcnPTpk016vr7NYQQZf5fLmtSekxMjHBzcxP29vZi0qRJYty4cRqTm6tycUFZ9f3998r169fFW2+9JWxsbISdnZ3o27evyMzMVB1bke1z7do10alTJ2FlZSU8PT3Ff/7zH434OLlZvyQhnhqsJSKqIY4ePYouXbogIyNDNTGViIwbEx8iqnEKCgpw9+5dDBkyBO7u7ti4caO+QyIiA8FVXURU43zzzTfw8vJCVlYW5s2bp+9wiMiAsMeHiIiIjAZ7fIiIiMhoMPEhIiIio8HEh4iIiIwGEx8iIiIyGkx8iIiIyGgw8SGiKjd06FD06tVLtR8aGorIyMgqj+PQoUOQJAlZWVnPPEaSJOzatUvra8bGxqJZs2Y6xZWWlgZJkir1mVtExoqJDxEBKElGJEmCJEmwsLCAj48PZs+ejeLi4kqve8eOHZgzZ45Wx2qTrBARPQsfUkpEKt26dUN8fDwKCgrwww8/YOzYsTA3N0d0dLTGsYWFhaonruvKycmpQq5DRPQi7PEhIhWZTAZ3d3d4eXlh9OjRCAsLw3fffQfgf8NTn376KTw8PNCwYUMAQEZGBvr16wcHBwc4OTmhZ8+eSEtLU11ToVBg8uTJcHBwgLOzM6ZOnYqn75v69FBXQUEBpk2bBk9PT8hkMvj4+OCrr75CWloaOnXqBABwdHSEJEkYOnQoAECpVCIuLg7169eHlZUVmjZtim3btqnV88MPP8DPzw9WVlbo1KmTWpzamjZtGvz8/GBtbY0GDRpgxowZKCoq0jhu1apV8PT0hLW1Nfr164fs7Gy117/88kv4+/vD0tISjRo1euZT3omoYjHxIaJnsrKyQmFhoWr/4MGDSE5Oxv79+/H999+jqKgI4eHhsLOzw9GjR3Hs2DHY2tqiW7duqvPmz5+PdevWYe3atfj111/x4MED7Ny587n1Dh48GN988w2WLFmCixcvYtWqVbC1tYWnpye2b98OAEhOTsatW7ewePFiAEBcXBw2bNiAlStX4vz585g0aRLee+89HD58GEBJgta7d29EREQgKSkJH3zwAaZPn17uNrGzs8O6detw4cIFLF68GGvWrMHChQvVjklJScHWrVuxe/du7Nu3D2fOnMGYMWNUr2/cuBExMTH49NNPcfHiRcydOxczZszA+vXryx0PEZWTHp8MT0QGZMiQIaJnz55CCCGUSqXYv3+/kMlkIioqSvW6m5ubKCgoUJ3z3//+VzRs2FAolUpVWUFBgbCyshI//vijEEKI2rVri3nz5qleLyoqEnXr1lXVJYQQISEhYuLEiUIIIZKTkwUAsX///jLj/OWXXwQA8fDhQ1VZfn6+sLa2FsePH1c7dvjw4WLAgAFCCCGio6NFQECA2uvTpk3TuNbTAIidO3c+8/XPP/9ctGzZUrU/c+ZMYWpqKm7cuKEq27t3rzAxMRG3bt0SQgjxyiuviE2bNqldZ86cOSI4OFgIIcS1a9cEAHHmzJln1ktEL4dzfIhI5fvvv4etrS2KioqgVCrx7rvvIjY2VvV6YGCg2ryeP/74AykpKbCzs1O7Tn5+Pq5evYrs7GzcunULbdq0Ub1mZmaGVq1aaQx3lUpKSoKpqSlCQkK0jjslJQV5eXno2rWrWnlhYSGaN28OALh48aJaHAAQHBysdR2ltmzZgiVLluDq1avIzc1FcXEx5HK52jH16tVDnTp11OpRKpVITk6GnZ0drl69iuHDh2PEiBGqY4qLi2Fvb1/ueIiofJj4EJFKp06dsGLFClhYWMDDwwNmZuq/ImxsbNT2c3Nz0bJlS2zcuFHjWq6uri8Vg5WVVbnPyc3NBQDs2bNHLeEASuYtVZSEhAQMHDgQs2bNQnh4OOzt7bF582bMnz+/3LGuWbNGIxEzNTWtsFiJqGxMfIhIxcbGBj4+Plof36JFC2zZsgW1atXS6PUoVbt2bZw8eRIdO3YEUNKzkZiYiBYtWpR5fGBgIJRKJQ4fPoywsDCN10t7nBQKhaosICAAMpkM6enpz+wp8vf3V03ULnXixIkXv8m/OX78OLy8vPCvf/1LVXb9+nWN49LT03Hz5k14eHio6jExMUHDhg3h5uYGDw8PpKamYuDAgeWqn4h0x8nNRPTSBg4cCBcXF/Ts2RNHjx7FtWvXcOjQIUyYMAE3btwAAEycOBGfffYZdu3ahUuXLmHMmDHPvQePt7c3hgwZgvfffx+7du1SXXPr1q0AAC8vL0iShO+//x53795Fbm4u7OzsEBUVhUmTJmH9+vW4evUqfv/9dyxdulQ1YXjUqFG4cuUKpkyZguTkZGzatAnr1q0r1/v19fVFeno6Nm/ejKtXr2LJkiVlTtS2tLTEkCFD8Mcff+Do0aOYMGEC+vXrB3d3dwDArFmzEBcXhyVLluDy5cs4e/Ys4uPjsWDBgnLFQ0Tlx8SHiF6atbU1jhw5gnr16qF3797w9/fH8OHDkZ+fr+oB+uijjzBo0CAMGTIEwcHBsLOzw9tvv/3c665YsQL/+Mc/MGbMGDRq1AgjRozA48ePAQB16tTBrFmzMH36dLi5uWHcuHEAgDlz5mDGjBmIi4uDv78/unXrhj179qB+/foASubdbN++Hbt27ULTpk2xcuVKzJ07t1zv96233sKkSZMwbtw4NGvWDMePH8eMGTM0jvPx8UHv3r3RvXt3vP766wgKClJbrv7BBx/gyy+/RHx8PAIDAxESEoJ169apYiWiyiOJZ80wJCIiIqph2ONDRERERoOJDxERERkNJj5ERERkNJj4EBERkdFg4kNERERGg4kPERERGQ0mPkRERGQ0mPgQERGR0WDiQ0REREaDiQ8REREZDSY+REREZDT+P2Y0GfMfbACNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(classification_report(y_test, pred_svc))\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, pred_svc)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(\n",
        "    confusion_matrix=confusion_matrix,\n",
        "    display_labels=['artifact', 'extrahs', 'extrasystole', 'murmur', 'normal'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38b2937",
      "metadata": {
        "id": "d38b2937",
        "outputId": "6a0511d8-f498-4089-b778-912bae75bb51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58.97435897435898"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "mod_tree = DecisionTreeClassifier()\n",
        "mod_tree.fit(X_train, y_train)\n",
        "tree_pred = mod_tree.predict(X_test)\n",
        "acc_tree = accuracy_score(y_test, tree_pred)\n",
        "acc_tree*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a8af06",
      "metadata": {
        "scrolled": true,
        "id": "e5a8af06",
        "outputId": "0437de2c-1a1d-4e3c-c521-ab1d3ea899a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Accuracy: %s 69.23076923076923\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(alpha=1, max_iter=1000)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = mlp.predict(X_test)\n",
        "mlp_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('- Accuracy: %s', mlp_test_accuracy*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d41e73da",
      "metadata": {
        "id": "d41e73da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27ef170",
      "metadata": {
        "scrolled": true,
        "id": "c27ef170",
        "outputId": "80c7a4be-cf3a-412f-f372-07399a8bc5fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model performance for Training set\n",
            "- Accuracy: 0.9166666666666666\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.7350427350427351\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "estimator_list = [\n",
        "    ('svm',mod_svc),\n",
        "    ('rf',mod_RF),\n",
        "    (\"ada\",mod_ada)\n",
        "]\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimator_list, final_estimator=LogisticRegression())\n",
        "# Train stacked model\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = stack_model.predict(X_train)\n",
        "y_test_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Training set model performance\n",
        "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "#stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
        "#stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "# Test set model performance\n",
        "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "#stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
        "#stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
        "#print('- MCC: %s' % stack_model_train_mcc)\n",
        "#print('- F1 score: %s' % stack_model_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
        "#print('- MCC: %s' % stack_model_test_mcc)\n",
        "#print('- F1 score: %s' % stack_model_test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472ae9b3",
      "metadata": {
        "id": "472ae9b3",
        "outputId": "4c0173f0-c3b6-4855-a060-4b688f4ea41d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1486: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    artifact       1.00      0.80      0.89        10\n",
            "     extrahs       0.00      0.00      0.00         5\n",
            "extrasystole       0.00      0.00      0.00         7\n",
            "      murmur       0.87      0.45      0.59        29\n",
            "      normal       0.69      0.98      0.81        66\n",
            "\n",
            "    accuracy                           0.74       117\n",
            "   macro avg       0.51      0.45      0.46       117\n",
            "weighted avg       0.69      0.74      0.68       117\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(classification_report(y_test, y_test_pred))\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(\n",
        "    confusion_matrix=confusion_matrix,\n",
        "    display_labels=['artifact', 'extrahs', 'extrasystole', 'murmur', 'normal'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628ed062",
      "metadata": {
        "scrolled": true,
        "id": "628ed062",
        "outputId": "526f0e12-6fba-434d-b5c4-97d0e2ddd9a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>73.504274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>76.068376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adaboost</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>74.358974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>58.119658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ANN</td>\n",
              "      <td>75.213677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Algorithm   Accuracy\n",
              "0       Logistic Regression  73.504274\n",
              "1             Random Forest  76.068376\n",
              "2                  Adaboost  66.666667\n",
              "3                       SVM  74.358974\n",
              "4  Decision Tree Classifier  58.119658\n",
              "5                       KNN  66.666667\n",
              "6                       ANN  75.213677"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ACC=pd.DataFrame({'Algorithm':['Logistic Regression', 'Random Forest','Adaboost','SVM', 'Decision Tree Classifier', 'KNN', 'ANN'],'Accuracy':[acc_logi*100,acc_RF*100,acc_ada*100,acc_svc*100, acc_tree*100, acc_knn*100, acc_ann*100]},columns=['Algorithm','Accuracy'])\n",
        "ACC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9938802",
      "metadata": {
        "id": "a9938802"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "040a1a6f",
      "metadata": {
        "id": "040a1a6f"
      },
      "outputs": [],
      "source": [
        "### Label Encoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb58219a",
      "metadata": {
        "id": "cb58219a"
      },
      "outputs": [],
      "source": [
        "# One hot encoding\n",
        "y=np.array(pd.get_dummies(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4a9706",
      "metadata": {
        "scrolled": true,
        "id": "7e4a9706",
        "outputId": "e8a2d3ff-c172-4285-9bcf-28fdd0c1b2d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64ceebc",
      "metadata": {
        "id": "e64ceebc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a577e81b",
      "metadata": {
        "id": "a577e81b"
      },
      "outputs": [],
      "source": [
        "y_train = np.argmax(y_train, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6596cd0",
      "metadata": {
        "scrolled": true,
        "id": "b6596cd0",
        "outputId": "809a38f6-024f-4bb4-e3cb-17785fc3ee1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.14.0'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " tf. __version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7863c16",
      "metadata": {
        "id": "f7863c16"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,LSTM,Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bff9fd8",
      "metadata": {
        "id": "3bff9fd8"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    LSTM(128, activation='tanh', return_sequences=True),\n",
        "    LSTM(64, activation='tanh', dropout=0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323262ef",
      "metadata": {
        "scrolled": true,
        "id": "323262ef",
        "outputId": "9ed86dc6-112c-44ae-d74c-edc48c09c046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8054 - loss: 0.4574 - val_accuracy: 0.7265 - val_loss: 0.9122\n",
            "Epoch 2/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.7810 - loss: 0.4932 - val_accuracy: 0.7265 - val_loss: 1.0633\n",
            "Epoch 3/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8029 - loss: 0.4989 - val_accuracy: 0.7179 - val_loss: 0.9791\n",
            "Epoch 4/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.7860 - loss: 0.5201 - val_accuracy: 0.7350 - val_loss: 0.8513\n",
            "Epoch 5/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.8047 - loss: 0.4833 - val_accuracy: 0.7179 - val_loss: 0.9921\n",
            "Epoch 6/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8053 - loss: 0.4677 - val_accuracy: 0.7265 - val_loss: 0.9276\n",
            "Epoch 7/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.7913 - loss: 0.5414 - val_accuracy: 0.7436 - val_loss: 0.9339\n",
            "Epoch 8/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8051 - loss: 0.4706 - val_accuracy: 0.7350 - val_loss: 0.9844\n",
            "Epoch 9/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.8069 - loss: 0.4837 - val_accuracy: 0.7350 - val_loss: 0.9248\n",
            "Epoch 10/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.8064 - loss: 0.4559 - val_accuracy: 0.7179 - val_loss: 1.1676\n",
            "Epoch 11/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.8117 - loss: 0.5024 - val_accuracy: 0.7179 - val_loss: 0.9400\n",
            "Epoch 12/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7837 - loss: 0.5746 - val_accuracy: 0.7350 - val_loss: 0.7586\n",
            "Epoch 13/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.7540 - loss: 0.6277 - val_accuracy: 0.7265 - val_loss: 0.8207\n",
            "Epoch 14/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.7625 - loss: 0.6094 - val_accuracy: 0.7179 - val_loss: 0.7849\n",
            "Epoch 15/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.7734 - loss: 0.5839 - val_accuracy: 0.7350 - val_loss: 0.7318\n",
            "Epoch 16/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.7751 - loss: 0.5577 - val_accuracy: 0.7350 - val_loss: 0.7236\n",
            "Epoch 17/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.7745 - loss: 0.5020 - val_accuracy: 0.7436 - val_loss: 0.7706\n",
            "Epoch 18/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.7714 - loss: 0.5455 - val_accuracy: 0.7179 - val_loss: 0.9092\n",
            "Epoch 19/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.7784 - loss: 0.5188 - val_accuracy: 0.7350 - val_loss: 0.8062\n",
            "Epoch 20/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.7804 - loss: 0.5283 - val_accuracy: 0.7350 - val_loss: 0.7425\n",
            "Epoch 21/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - accuracy: 0.7824 - loss: 0.5140 - val_accuracy: 0.7265 - val_loss: 0.8859\n",
            "Epoch 22/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 185ms/step - accuracy: 0.8029 - loss: 0.4582 - val_accuracy: 0.7179 - val_loss: 0.8375\n",
            "Epoch 23/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 189ms/step - accuracy: 0.8106 - loss: 0.4895 - val_accuracy: 0.7179 - val_loss: 0.8740\n",
            "Epoch 24/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.8084 - loss: 0.4615 - val_accuracy: 0.7436 - val_loss: 0.8930\n",
            "Epoch 25/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7756 - loss: 0.4929 - val_accuracy: 0.7265 - val_loss: 0.8265\n",
            "Epoch 26/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - accuracy: 0.7709 - loss: 0.5215 - val_accuracy: 0.7179 - val_loss: 0.9665\n",
            "Epoch 27/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.7898 - loss: 0.4596 - val_accuracy: 0.7179 - val_loss: 0.9543\n",
            "Epoch 28/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.7874 - loss: 0.4532 - val_accuracy: 0.7350 - val_loss: 1.0849\n",
            "Epoch 29/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.8081 - loss: 0.4452 - val_accuracy: 0.7179 - val_loss: 0.8838\n",
            "Epoch 30/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 187ms/step - accuracy: 0.8153 - loss: 0.4143 - val_accuracy: 0.7179 - val_loss: 0.9707\n",
            "Epoch 31/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.7939 - loss: 0.4424 - val_accuracy: 0.7179 - val_loss: 1.0100\n",
            "Epoch 32/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - accuracy: 0.8041 - loss: 0.4463 - val_accuracy: 0.7094 - val_loss: 1.0836\n",
            "Epoch 33/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - accuracy: 0.8303 - loss: 0.3803 - val_accuracy: 0.7350 - val_loss: 0.9746\n",
            "Epoch 34/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - accuracy: 0.7992 - loss: 0.4498 - val_accuracy: 0.7009 - val_loss: 1.0658\n",
            "Epoch 35/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step - accuracy: 0.8331 - loss: 0.3927 - val_accuracy: 0.7009 - val_loss: 1.1266\n",
            "Epoch 36/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.7685 - loss: 0.5128 - val_accuracy: 0.7094 - val_loss: 1.0038\n",
            "Epoch 37/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.7756 - loss: 0.5169 - val_accuracy: 0.7265 - val_loss: 0.9770\n",
            "Epoch 38/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.8106 - loss: 0.4545 - val_accuracy: 0.7094 - val_loss: 1.0308\n",
            "Epoch 39/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - accuracy: 0.7918 - loss: 0.4663 - val_accuracy: 0.7179 - val_loss: 1.0768\n",
            "Epoch 40/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - accuracy: 0.8300 - loss: 0.3811 - val_accuracy: 0.7265 - val_loss: 1.0170\n",
            "Epoch 41/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 185ms/step - accuracy: 0.8224 - loss: 0.3744 - val_accuracy: 0.7179 - val_loss: 1.0916\n",
            "Epoch 42/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - accuracy: 0.8228 - loss: 0.4088 - val_accuracy: 0.7436 - val_loss: 0.9990\n",
            "Epoch 43/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8171 - loss: 0.4229 - val_accuracy: 0.6923 - val_loss: 1.0448\n",
            "Epoch 44/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.8226 - loss: 0.3910 - val_accuracy: 0.7350 - val_loss: 1.0616\n",
            "Epoch 45/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8385 - loss: 0.3660 - val_accuracy: 0.7009 - val_loss: 1.1607\n",
            "Epoch 46/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.8320 - loss: 0.4066 - val_accuracy: 0.7350 - val_loss: 1.1439\n",
            "Epoch 47/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - accuracy: 0.8269 - loss: 0.3944 - val_accuracy: 0.7179 - val_loss: 1.1013\n",
            "Epoch 48/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.8456 - loss: 0.3799 - val_accuracy: 0.7265 - val_loss: 1.0422\n",
            "Epoch 49/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.8518 - loss: 0.3605 - val_accuracy: 0.7094 - val_loss: 1.0511\n",
            "Epoch 50/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.8579 - loss: 0.3563 - val_accuracy: 0.6838 - val_loss: 1.0762\n",
            "Epoch 51/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - accuracy: 0.8182 - loss: 0.4260 - val_accuracy: 0.7436 - val_loss: 1.0774\n",
            "Epoch 52/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8418 - loss: 0.3517 - val_accuracy: 0.7265 - val_loss: 1.1889\n",
            "Epoch 53/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8489 - loss: 0.3093 - val_accuracy: 0.7350 - val_loss: 1.2885\n",
            "Epoch 54/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8619 - loss: 0.3095 - val_accuracy: 0.6410 - val_loss: 1.3647\n",
            "Epoch 55/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8562 - loss: 0.3198 - val_accuracy: 0.7179 - val_loss: 1.2642\n",
            "Epoch 56/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8724 - loss: 0.3017 - val_accuracy: 0.6923 - val_loss: 1.2056\n",
            "Epoch 57/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.8486 - loss: 0.3483 - val_accuracy: 0.7265 - val_loss: 1.1406\n",
            "Epoch 58/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - accuracy: 0.8164 - loss: 0.3661 - val_accuracy: 0.6923 - val_loss: 1.0502\n",
            "Epoch 59/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.8016 - loss: 0.3485 - val_accuracy: 0.7094 - val_loss: 1.3769\n",
            "Epoch 60/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.8372 - loss: 0.3650 - val_accuracy: 0.7265 - val_loss: 1.2759\n",
            "Epoch 61/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - accuracy: 0.7943 - loss: 0.4297 - val_accuracy: 0.7350 - val_loss: 1.2140\n",
            "Epoch 62/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step - accuracy: 0.8309 - loss: 0.3765 - val_accuracy: 0.7009 - val_loss: 1.2084\n",
            "Epoch 63/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.8087 - loss: 0.4027 - val_accuracy: 0.6752 - val_loss: 1.0876\n",
            "Epoch 64/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8695 - loss: 0.3510 - val_accuracy: 0.6923 - val_loss: 1.1834\n",
            "Epoch 65/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8326 - loss: 0.3687 - val_accuracy: 0.7094 - val_loss: 1.1876\n",
            "Epoch 66/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8636 - loss: 0.2993 - val_accuracy: 0.7265 - val_loss: 1.1818\n",
            "Epoch 67/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8892 - loss: 0.2885 - val_accuracy: 0.6923 - val_loss: 1.2550\n",
            "Epoch 68/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8904 - loss: 0.2756 - val_accuracy: 0.7094 - val_loss: 1.2134\n",
            "Epoch 69/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.8742 - loss: 0.2893 - val_accuracy: 0.7094 - val_loss: 1.3695\n",
            "Epoch 70/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.8861 - loss: 0.2681 - val_accuracy: 0.7265 - val_loss: 1.3305\n",
            "Epoch 71/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.8817 - loss: 0.3022 - val_accuracy: 0.7265 - val_loss: 1.3009\n",
            "Epoch 72/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9008 - loss: 0.2710 - val_accuracy: 0.7179 - val_loss: 1.2890\n",
            "Epoch 73/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8987 - loss: 0.2426 - val_accuracy: 0.6667 - val_loss: 1.4030\n",
            "Epoch 74/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8767 - loss: 0.3004 - val_accuracy: 0.6496 - val_loss: 1.3672\n",
            "Epoch 75/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.8523 - loss: 0.3146 - val_accuracy: 0.6667 - val_loss: 1.4577\n",
            "Epoch 76/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8859 - loss: 0.2631 - val_accuracy: 0.6581 - val_loss: 1.5239\n",
            "Epoch 77/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8951 - loss: 0.2528 - val_accuracy: 0.6923 - val_loss: 1.2787\n",
            "Epoch 78/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8764 - loss: 0.2711 - val_accuracy: 0.6667 - val_loss: 1.5623\n",
            "Epoch 79/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8791 - loss: 0.2679 - val_accuracy: 0.6581 - val_loss: 1.4994\n",
            "Epoch 80/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9094 - loss: 0.2360 - val_accuracy: 0.6667 - val_loss: 1.6049\n",
            "Epoch 81/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8932 - loss: 0.2374 - val_accuracy: 0.6667 - val_loss: 1.5867\n",
            "Epoch 82/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9141 - loss: 0.2332 - val_accuracy: 0.6410 - val_loss: 1.4822\n",
            "Epoch 83/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8718 - loss: 0.3126 - val_accuracy: 0.6923 - val_loss: 1.5412\n",
            "Epoch 84/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8813 - loss: 0.2895 - val_accuracy: 0.6581 - val_loss: 1.5643\n",
            "Epoch 85/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.8986 - loss: 0.2333 - val_accuracy: 0.6581 - val_loss: 1.7822\n",
            "Epoch 86/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.8651 - loss: 0.3834 - val_accuracy: 0.6923 - val_loss: 1.5462\n",
            "Epoch 87/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9008 - loss: 0.2254 - val_accuracy: 0.6923 - val_loss: 1.4764\n",
            "Epoch 88/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9056 - loss: 0.2245 - val_accuracy: 0.7009 - val_loss: 1.5727\n",
            "Epoch 89/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.8785 - loss: 0.2755 - val_accuracy: 0.6838 - val_loss: 1.6484\n",
            "Epoch 90/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9247 - loss: 0.2205 - val_accuracy: 0.7094 - val_loss: 1.5245\n",
            "Epoch 91/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8657 - loss: 0.3023 - val_accuracy: 0.7009 - val_loss: 1.3355\n",
            "Epoch 92/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9043 - loss: 0.2708 - val_accuracy: 0.7265 - val_loss: 1.4908\n",
            "Epoch 93/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9092 - loss: 0.2824 - val_accuracy: 0.7094 - val_loss: 1.3642\n",
            "Epoch 94/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9099 - loss: 0.2462 - val_accuracy: 0.7607 - val_loss: 1.4909\n",
            "Epoch 95/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9032 - loss: 0.2284 - val_accuracy: 0.6581 - val_loss: 1.6367\n",
            "Epoch 96/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9276 - loss: 0.1886 - val_accuracy: 0.6325 - val_loss: 1.7656\n",
            "Epoch 97/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8807 - loss: 0.3331 - val_accuracy: 0.6581 - val_loss: 1.5084\n",
            "Epoch 98/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9054 - loss: 0.2758 - val_accuracy: 0.6496 - val_loss: 1.5475\n",
            "Epoch 99/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.8968 - loss: 0.2373 - val_accuracy: 0.6325 - val_loss: 1.4670\n",
            "Epoch 100/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.8992 - loss: 0.2050 - val_accuracy: 0.6752 - val_loss: 1.6682\n",
            "Epoch 101/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9436 - loss: 0.1855 - val_accuracy: 0.7009 - val_loss: 1.7003\n",
            "Epoch 102/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - accuracy: 0.9244 - loss: 0.1922 - val_accuracy: 0.6752 - val_loss: 1.9075\n",
            "Epoch 103/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.9444 - loss: 0.1672 - val_accuracy: 0.6923 - val_loss: 1.9651\n",
            "Epoch 104/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9450 - loss: 0.1891 - val_accuracy: 0.6581 - val_loss: 1.7027\n",
            "Epoch 105/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.9311 - loss: 0.2558 - val_accuracy: 0.6838 - val_loss: 1.7653\n",
            "Epoch 106/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - accuracy: 0.9580 - loss: 0.1528 - val_accuracy: 0.6154 - val_loss: 1.8769\n",
            "Epoch 107/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.9455 - loss: 0.1581 - val_accuracy: 0.6752 - val_loss: 1.8853\n",
            "Epoch 108/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - accuracy: 0.9444 - loss: 0.1691 - val_accuracy: 0.6923 - val_loss: 1.6917\n",
            "Epoch 109/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.9130 - loss: 0.2893 - val_accuracy: 0.6496 - val_loss: 1.7520\n",
            "Epoch 110/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.8986 - loss: 0.2997 - val_accuracy: 0.6752 - val_loss: 1.6158\n",
            "Epoch 111/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.9079 - loss: 0.2370 - val_accuracy: 0.6581 - val_loss: 1.7079\n",
            "Epoch 112/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9429 - loss: 0.1708 - val_accuracy: 0.6496 - val_loss: 1.7618\n",
            "Epoch 113/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9303 - loss: 0.1530 - val_accuracy: 0.6923 - val_loss: 1.8330\n",
            "Epoch 114/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9591 - loss: 0.1338 - val_accuracy: 0.6667 - val_loss: 1.9172\n",
            "Epoch 115/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - accuracy: 0.9463 - loss: 0.1448 - val_accuracy: 0.6838 - val_loss: 1.9633\n",
            "Epoch 116/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.9648 - loss: 0.1159 - val_accuracy: 0.6667 - val_loss: 2.0474\n",
            "Epoch 117/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9590 - loss: 0.1333 - val_accuracy: 0.6838 - val_loss: 2.0959\n",
            "Epoch 118/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.9726 - loss: 0.0898 - val_accuracy: 0.6496 - val_loss: 2.1999\n",
            "Epoch 119/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9587 - loss: 0.1152 - val_accuracy: 0.6923 - val_loss: 2.2026\n",
            "Epoch 120/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9518 - loss: 0.1361 - val_accuracy: 0.6410 - val_loss: 2.1376\n",
            "Epoch 121/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9418 - loss: 0.1470 - val_accuracy: 0.6923 - val_loss: 2.1973\n",
            "Epoch 122/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.9355 - loss: 0.1919 - val_accuracy: 0.6068 - val_loss: 2.0948\n",
            "Epoch 123/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9195 - loss: 0.2225 - val_accuracy: 0.7009 - val_loss: 1.8728\n",
            "Epoch 124/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9053 - loss: 0.2661 - val_accuracy: 0.6752 - val_loss: 2.0077\n",
            "Epoch 125/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8701 - loss: 0.3483 - val_accuracy: 0.6581 - val_loss: 1.7448\n",
            "Epoch 126/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8895 - loss: 0.2394 - val_accuracy: 0.6239 - val_loss: 1.7101\n",
            "Epoch 127/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.8720 - loss: 0.3116 - val_accuracy: 0.6923 - val_loss: 1.7014\n",
            "Epoch 128/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 177ms/step - accuracy: 0.9310 - loss: 0.2342 - val_accuracy: 0.6496 - val_loss: 1.8142\n",
            "Epoch 129/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - accuracy: 0.9301 - loss: 0.1830 - val_accuracy: 0.6410 - val_loss: 1.8788\n",
            "Epoch 130/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 338ms/step - accuracy: 0.9423 - loss: 0.1804 - val_accuracy: 0.6410 - val_loss: 1.9685\n",
            "Epoch 131/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 238ms/step - accuracy: 0.9518 - loss: 0.1413 - val_accuracy: 0.6667 - val_loss: 1.8785\n",
            "Epoch 132/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 242ms/step - accuracy: 0.9460 - loss: 0.1339 - val_accuracy: 0.6496 - val_loss: 1.7848\n",
            "Epoch 133/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 455ms/step - accuracy: 0.9344 - loss: 0.1916 - val_accuracy: 0.6752 - val_loss: 1.8341\n",
            "Epoch 134/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9381 - loss: 0.2129 - val_accuracy: 0.6239 - val_loss: 1.9695\n",
            "Epoch 135/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.9420 - loss: 0.1472 - val_accuracy: 0.6410 - val_loss: 2.0081\n",
            "Epoch 136/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 0.9516 - loss: 0.1159 - val_accuracy: 0.6068 - val_loss: 2.1735\n",
            "Epoch 137/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 229ms/step - accuracy: 0.9445 - loss: 0.1370 - val_accuracy: 0.6667 - val_loss: 2.1741\n",
            "Epoch 138/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.9566 - loss: 0.1602 - val_accuracy: 0.6154 - val_loss: 2.1741\n",
            "Epoch 139/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.9339 - loss: 0.2182 - val_accuracy: 0.6239 - val_loss: 2.1086\n",
            "Epoch 140/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - accuracy: 0.9501 - loss: 0.1290 - val_accuracy: 0.6239 - val_loss: 2.2385\n",
            "Epoch 141/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.9390 - loss: 0.2008 - val_accuracy: 0.6410 - val_loss: 2.0707\n",
            "Epoch 142/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - accuracy: 0.9740 - loss: 0.0903 - val_accuracy: 0.6325 - val_loss: 2.0614\n",
            "Epoch 143/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.9502 - loss: 0.1400 - val_accuracy: 0.6068 - val_loss: 2.1660\n",
            "Epoch 144/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 182ms/step - accuracy: 0.9516 - loss: 0.1302 - val_accuracy: 0.6410 - val_loss: 2.1607\n",
            "Epoch 145/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9131 - loss: 0.2754 - val_accuracy: 0.5812 - val_loss: 2.1835\n",
            "Epoch 146/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 0.8953 - loss: 0.3302 - val_accuracy: 0.6581 - val_loss: 1.6669\n",
            "Epoch 147/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - accuracy: 0.9025 - loss: 0.2429 - val_accuracy: 0.6752 - val_loss: 1.3721\n",
            "Epoch 148/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - accuracy: 0.9179 - loss: 0.2337 - val_accuracy: 0.6752 - val_loss: 1.5801\n",
            "Epoch 149/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 191ms/step - accuracy: 0.9289 - loss: 0.1758 - val_accuracy: 0.6581 - val_loss: 1.6208\n",
            "Epoch 150/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.9726 - loss: 0.1350 - val_accuracy: 0.7009 - val_loss: 1.6844\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x243d5211f90>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "num_epochs = 150\n",
        "num_batch_size = 32\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a71a316",
      "metadata": {
        "id": "6a71a316",
        "outputId": "c8e31c0a-ef31-4b10-f44c-b375290438dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6762 - loss: 1.6288\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7008547186851501"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=1)\n",
        "acc_lstm = test_accuracy[1]\n",
        "acc_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0470ac60",
      "metadata": {
        "id": "0470ac60"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True)),\n",
        "    Bidirectional(LSTM(64, activation='tanh', dropout=0.5)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74952f98",
      "metadata": {
        "scrolled": true,
        "id": "74952f98",
        "outputId": "b95f4897-9af5-47f0-8153-59af022e270e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 178ms/step - accuracy: 0.4266 - loss: 1.3764 - val_accuracy: 0.5812 - val_loss: 0.9970\n",
            "Epoch 2/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.5267 - loss: 1.1065 - val_accuracy: 0.6496 - val_loss: 0.9551\n",
            "Epoch 3/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.6343 - loss: 0.9740 - val_accuracy: 0.6496 - val_loss: 0.8624\n",
            "Epoch 4/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6533 - loss: 0.9658 - val_accuracy: 0.6752 - val_loss: 0.8557\n",
            "Epoch 5/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.6481 - loss: 0.9760 - val_accuracy: 0.6752 - val_loss: 0.8143\n",
            "Epoch 6/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6539 - loss: 0.9398 - val_accuracy: 0.6410 - val_loss: 0.8458\n",
            "Epoch 7/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.6729 - loss: 0.9373 - val_accuracy: 0.6496 - val_loss: 0.8416\n",
            "Epoch 8/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.6510 - loss: 0.9350 - val_accuracy: 0.6410 - val_loss: 0.8033\n",
            "Epoch 9/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.6427 - loss: 0.9485 - val_accuracy: 0.7094 - val_loss: 0.7772\n",
            "Epoch 10/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.6478 - loss: 0.9347 - val_accuracy: 0.6838 - val_loss: 0.7749\n",
            "Epoch 11/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.6801 - loss: 0.8333 - val_accuracy: 0.7094 - val_loss: 0.7540\n",
            "Epoch 12/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.6871 - loss: 0.8570 - val_accuracy: 0.7179 - val_loss: 0.7868\n",
            "Epoch 13/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.6821 - loss: 0.8798 - val_accuracy: 0.7265 - val_loss: 0.7473\n",
            "Epoch 14/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - accuracy: 0.7007 - loss: 0.8404 - val_accuracy: 0.7350 - val_loss: 0.7385\n",
            "Epoch 15/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.7153 - loss: 0.8218 - val_accuracy: 0.6838 - val_loss: 0.7427\n",
            "Epoch 16/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - accuracy: 0.6604 - loss: 0.8533 - val_accuracy: 0.6752 - val_loss: 0.7578\n",
            "Epoch 17/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.7022 - loss: 0.8314 - val_accuracy: 0.6923 - val_loss: 0.7321\n",
            "Epoch 18/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - accuracy: 0.6622 - loss: 0.8716 - val_accuracy: 0.7009 - val_loss: 0.7492\n",
            "Epoch 19/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - accuracy: 0.6811 - loss: 0.8659 - val_accuracy: 0.6923 - val_loss: 0.7447\n",
            "Epoch 20/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7307 - loss: 0.7925 - val_accuracy: 0.7009 - val_loss: 0.7289\n",
            "Epoch 21/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.6908 - loss: 0.8215 - val_accuracy: 0.6923 - val_loss: 0.7168\n",
            "Epoch 22/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.7095 - loss: 0.8214 - val_accuracy: 0.7094 - val_loss: 0.7109\n",
            "Epoch 23/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.7098 - loss: 0.8056 - val_accuracy: 0.7265 - val_loss: 0.7307\n",
            "Epoch 24/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.7021 - loss: 0.8125 - val_accuracy: 0.6923 - val_loss: 0.7180\n",
            "Epoch 25/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - accuracy: 0.7494 - loss: 0.7354 - val_accuracy: 0.6752 - val_loss: 0.7182\n",
            "Epoch 26/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7166 - loss: 0.7808 - val_accuracy: 0.6923 - val_loss: 0.7215\n",
            "Epoch 27/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - accuracy: 0.6972 - loss: 0.8113 - val_accuracy: 0.6923 - val_loss: 0.7200\n",
            "Epoch 28/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - accuracy: 0.7023 - loss: 0.8163 - val_accuracy: 0.6667 - val_loss: 0.7027\n",
            "Epoch 29/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 0.7347 - loss: 0.7298 - val_accuracy: 0.6410 - val_loss: 0.7699\n",
            "Epoch 30/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - accuracy: 0.6989 - loss: 0.8248 - val_accuracy: 0.6923 - val_loss: 0.7246\n",
            "Epoch 31/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - accuracy: 0.6950 - loss: 0.7838 - val_accuracy: 0.7094 - val_loss: 0.7291\n",
            "Epoch 32/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7085 - loss: 0.8026 - val_accuracy: 0.6923 - val_loss: 0.7222\n",
            "Epoch 33/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6990 - loss: 0.7886 - val_accuracy: 0.7179 - val_loss: 0.7287\n",
            "Epoch 34/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - accuracy: 0.7212 - loss: 0.7815 - val_accuracy: 0.7179 - val_loss: 0.7010\n",
            "Epoch 35/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - accuracy: 0.6952 - loss: 0.7813 - val_accuracy: 0.7179 - val_loss: 0.6944\n",
            "Epoch 36/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.7085 - loss: 0.7956 - val_accuracy: 0.6838 - val_loss: 0.7237\n",
            "Epoch 37/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.7442 - loss: 0.7225 - val_accuracy: 0.7179 - val_loss: 0.7176\n",
            "Epoch 38/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.7299 - loss: 0.7516 - val_accuracy: 0.7179 - val_loss: 0.7000\n",
            "Epoch 39/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.7058 - loss: 0.7588 - val_accuracy: 0.7094 - val_loss: 0.7193\n",
            "Epoch 40/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.7134 - loss: 0.7692 - val_accuracy: 0.7009 - val_loss: 0.7100\n",
            "Epoch 41/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.7212 - loss: 0.7500 - val_accuracy: 0.7350 - val_loss: 0.7232\n",
            "Epoch 42/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.7567 - loss: 0.7315 - val_accuracy: 0.7265 - val_loss: 0.6956\n",
            "Epoch 43/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7340 - loss: 0.7375 - val_accuracy: 0.6923 - val_loss: 0.7144\n",
            "Epoch 44/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 0.6991 - loss: 0.8032 - val_accuracy: 0.7265 - val_loss: 0.7332\n",
            "Epoch 45/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.6951 - loss: 0.7830 - val_accuracy: 0.7094 - val_loss: 0.7056\n",
            "Epoch 46/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.6965 - loss: 0.8118 - val_accuracy: 0.6838 - val_loss: 0.7524\n",
            "Epoch 47/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.7007 - loss: 0.8102 - val_accuracy: 0.6667 - val_loss: 0.7193\n",
            "Epoch 48/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - accuracy: 0.6917 - loss: 0.7273 - val_accuracy: 0.7009 - val_loss: 0.7007\n",
            "Epoch 49/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.7237 - loss: 0.6862 - val_accuracy: 0.6667 - val_loss: 0.7102\n",
            "Epoch 50/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.7261 - loss: 0.7027 - val_accuracy: 0.6923 - val_loss: 0.7305\n",
            "Epoch 51/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.7417 - loss: 0.7407 - val_accuracy: 0.7009 - val_loss: 0.7377\n",
            "Epoch 52/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.7089 - loss: 0.7695 - val_accuracy: 0.6923 - val_loss: 0.7294\n",
            "Epoch 53/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.7283 - loss: 0.7501 - val_accuracy: 0.7094 - val_loss: 0.7186\n",
            "Epoch 54/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.7485 - loss: 0.6834 - val_accuracy: 0.7179 - val_loss: 0.7049\n",
            "Epoch 55/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.7331 - loss: 0.7199 - val_accuracy: 0.7265 - val_loss: 0.7199\n",
            "Epoch 56/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.6876 - loss: 0.7790 - val_accuracy: 0.7009 - val_loss: 0.7058\n",
            "Epoch 57/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.7565 - loss: 0.7062 - val_accuracy: 0.7350 - val_loss: 0.7018\n",
            "Epoch 58/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.6658 - loss: 0.7769 - val_accuracy: 0.7094 - val_loss: 0.7265\n",
            "Epoch 59/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.7041 - loss: 0.7711 - val_accuracy: 0.7009 - val_loss: 0.7314\n",
            "Epoch 60/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.7199 - loss: 0.7257 - val_accuracy: 0.7265 - val_loss: 0.7032\n",
            "Epoch 61/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7615 - loss: 0.6822 - val_accuracy: 0.7094 - val_loss: 0.7176\n",
            "Epoch 62/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.7597 - loss: 0.6540 - val_accuracy: 0.6667 - val_loss: 0.7195\n",
            "Epoch 63/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.7651 - loss: 0.6395 - val_accuracy: 0.7265 - val_loss: 0.6965\n",
            "Epoch 64/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.7575 - loss: 0.6873 - val_accuracy: 0.7179 - val_loss: 0.7035\n",
            "Epoch 65/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.7365 - loss: 0.6963 - val_accuracy: 0.7179 - val_loss: 0.7346\n",
            "Epoch 66/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7546 - loss: 0.6653 - val_accuracy: 0.7179 - val_loss: 0.7232\n",
            "Epoch 67/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.7150 - loss: 0.7037 - val_accuracy: 0.7350 - val_loss: 0.7174\n",
            "Epoch 68/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7476 - loss: 0.6535 - val_accuracy: 0.7521 - val_loss: 0.7173\n",
            "Epoch 69/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7410 - loss: 0.6928 - val_accuracy: 0.7265 - val_loss: 0.7127\n",
            "Epoch 70/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7612 - loss: 0.6658 - val_accuracy: 0.7350 - val_loss: 0.7029\n",
            "Epoch 71/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7624 - loss: 0.6601 - val_accuracy: 0.7350 - val_loss: 0.6942\n",
            "Epoch 72/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.7667 - loss: 0.6380 - val_accuracy: 0.7179 - val_loss: 0.7175\n",
            "Epoch 73/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.7431 - loss: 0.6734 - val_accuracy: 0.7265 - val_loss: 0.7188\n",
            "Epoch 74/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.7590 - loss: 0.6571 - val_accuracy: 0.7094 - val_loss: 0.7274\n",
            "Epoch 75/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7324 - loss: 0.6871 - val_accuracy: 0.7094 - val_loss: 0.7010\n",
            "Epoch 76/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7540 - loss: 0.6067 - val_accuracy: 0.7436 - val_loss: 0.7196\n",
            "Epoch 77/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.7378 - loss: 0.6766 - val_accuracy: 0.7179 - val_loss: 0.7071\n",
            "Epoch 78/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.7280 - loss: 0.6477 - val_accuracy: 0.7521 - val_loss: 0.6828\n",
            "Epoch 79/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.7427 - loss: 0.6874 - val_accuracy: 0.7436 - val_loss: 0.7106\n",
            "Epoch 80/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.7753 - loss: 0.6459 - val_accuracy: 0.7179 - val_loss: 0.7551\n",
            "Epoch 81/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.7297 - loss: 0.6835 - val_accuracy: 0.7350 - val_loss: 0.6831\n",
            "Epoch 82/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7498 - loss: 0.6456 - val_accuracy: 0.7350 - val_loss: 0.6906\n",
            "Epoch 83/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7698 - loss: 0.5880 - val_accuracy: 0.7265 - val_loss: 0.7182\n",
            "Epoch 84/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7422 - loss: 0.6382 - val_accuracy: 0.7521 - val_loss: 0.6582\n",
            "Epoch 85/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7391 - loss: 0.6597 - val_accuracy: 0.7350 - val_loss: 0.6709\n",
            "Epoch 86/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7737 - loss: 0.6064 - val_accuracy: 0.7350 - val_loss: 0.7051\n",
            "Epoch 87/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7868 - loss: 0.5960 - val_accuracy: 0.7436 - val_loss: 0.6986\n",
            "Epoch 88/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.6211 - val_accuracy: 0.7436 - val_loss: 0.6986\n",
            "Epoch 89/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.7898 - loss: 0.6000 - val_accuracy: 0.7265 - val_loss: 0.7634\n",
            "Epoch 90/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.7736 - loss: 0.6234 - val_accuracy: 0.7436 - val_loss: 0.7106\n",
            "Epoch 91/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7573 - loss: 0.6578 - val_accuracy: 0.7350 - val_loss: 0.7673\n",
            "Epoch 92/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7470 - loss: 0.6272 - val_accuracy: 0.7350 - val_loss: 0.7483\n",
            "Epoch 93/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.7741 - loss: 0.5846 - val_accuracy: 0.7607 - val_loss: 0.7165\n",
            "Epoch 94/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.7904 - loss: 0.5632 - val_accuracy: 0.7179 - val_loss: 0.7248\n",
            "Epoch 95/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.7862 - loss: 0.5653 - val_accuracy: 0.7265 - val_loss: 0.7181\n",
            "Epoch 96/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7621 - loss: 0.6165 - val_accuracy: 0.7265 - val_loss: 0.7134\n",
            "Epoch 97/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.7506 - loss: 0.6096 - val_accuracy: 0.7265 - val_loss: 0.6982\n",
            "Epoch 98/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7820 - loss: 0.5517 - val_accuracy: 0.7350 - val_loss: 0.7375\n",
            "Epoch 99/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7593 - loss: 0.6117 - val_accuracy: 0.7265 - val_loss: 0.7504\n",
            "Epoch 100/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7376 - loss: 0.6728 - val_accuracy: 0.7265 - val_loss: 0.7816\n",
            "Epoch 101/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7367 - loss: 0.6763 - val_accuracy: 0.7265 - val_loss: 0.7147\n",
            "Epoch 102/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7638 - loss: 0.6277 - val_accuracy: 0.7436 - val_loss: 0.6916\n",
            "Epoch 103/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7515 - loss: 0.6271 - val_accuracy: 0.7265 - val_loss: 0.7111\n",
            "Epoch 104/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7842 - loss: 0.5475 - val_accuracy: 0.7350 - val_loss: 0.7154\n",
            "Epoch 105/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7617 - loss: 0.5982 - val_accuracy: 0.7265 - val_loss: 0.7002\n",
            "Epoch 106/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7941 - loss: 0.5954 - val_accuracy: 0.7094 - val_loss: 0.8061\n",
            "Epoch 107/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7473 - loss: 0.6440 - val_accuracy: 0.7265 - val_loss: 0.7726\n",
            "Epoch 108/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7584 - loss: 0.5976 - val_accuracy: 0.7265 - val_loss: 0.7492\n",
            "Epoch 109/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.7743 - loss: 0.5838 - val_accuracy: 0.7436 - val_loss: 0.7454\n",
            "Epoch 110/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.7968 - loss: 0.5403 - val_accuracy: 0.7350 - val_loss: 0.7521\n",
            "Epoch 111/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7695 - loss: 0.6463 - val_accuracy: 0.7094 - val_loss: 0.8610\n",
            "Epoch 112/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7057 - loss: 0.7507 - val_accuracy: 0.7350 - val_loss: 0.7301\n",
            "Epoch 113/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7356 - loss: 0.6457 - val_accuracy: 0.7436 - val_loss: 0.6988\n",
            "Epoch 114/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7673 - loss: 0.6035 - val_accuracy: 0.7350 - val_loss: 0.6723\n",
            "Epoch 115/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7791 - loss: 0.5875 - val_accuracy: 0.7436 - val_loss: 0.7042\n",
            "Epoch 116/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7853 - loss: 0.5526 - val_accuracy: 0.7607 - val_loss: 0.7149\n",
            "Epoch 117/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7604 - loss: 0.6134 - val_accuracy: 0.7607 - val_loss: 0.6721\n",
            "Epoch 118/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.8142 - loss: 0.5285 - val_accuracy: 0.7350 - val_loss: 0.6961\n",
            "Epoch 119/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - accuracy: 0.7753 - loss: 0.6065 - val_accuracy: 0.7265 - val_loss: 0.6781\n",
            "Epoch 120/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - accuracy: 0.7797 - loss: 0.5608 - val_accuracy: 0.7521 - val_loss: 0.7523\n",
            "Epoch 121/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.7989 - loss: 0.5296 - val_accuracy: 0.7436 - val_loss: 0.7759\n",
            "Epoch 122/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - accuracy: 0.7940 - loss: 0.5474 - val_accuracy: 0.7265 - val_loss: 0.7798\n",
            "Epoch 123/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.7713 - loss: 0.6277 - val_accuracy: 0.7521 - val_loss: 0.6981\n",
            "Epoch 124/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.7841 - loss: 0.5831 - val_accuracy: 0.7521 - val_loss: 0.6992\n",
            "Epoch 125/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.7834 - loss: 0.5515 - val_accuracy: 0.7521 - val_loss: 0.7596\n",
            "Epoch 126/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.7888 - loss: 0.5510 - val_accuracy: 0.7265 - val_loss: 0.7860\n",
            "Epoch 127/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.7772 - loss: 0.5604 - val_accuracy: 0.7436 - val_loss: 0.8020\n",
            "Epoch 128/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7574 - loss: 0.6322 - val_accuracy: 0.7350 - val_loss: 0.7353\n",
            "Epoch 129/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7553 - loss: 0.6257 - val_accuracy: 0.7350 - val_loss: 0.7624\n",
            "Epoch 130/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7754 - loss: 0.5874 - val_accuracy: 0.7179 - val_loss: 0.7893\n",
            "Epoch 131/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.8216 - loss: 0.5172 - val_accuracy: 0.7179 - val_loss: 0.7691\n",
            "Epoch 132/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7688 - loss: 0.5656 - val_accuracy: 0.7350 - val_loss: 0.7882\n",
            "Epoch 133/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - accuracy: 0.7591 - loss: 0.5606 - val_accuracy: 0.7179 - val_loss: 0.8552\n",
            "Epoch 134/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - accuracy: 0.7712 - loss: 0.5733 - val_accuracy: 0.7350 - val_loss: 0.8456\n",
            "Epoch 135/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.7965 - loss: 0.4974 - val_accuracy: 0.7350 - val_loss: 0.8437\n",
            "Epoch 136/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.8068 - loss: 0.4966 - val_accuracy: 0.7179 - val_loss: 0.8483\n",
            "Epoch 137/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.8057 - loss: 0.5025 - val_accuracy: 0.7265 - val_loss: 0.9247\n",
            "Epoch 138/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8109 - loss: 0.4943 - val_accuracy: 0.7179 - val_loss: 0.8804\n",
            "Epoch 139/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - accuracy: 0.7438 - loss: 0.5659 - val_accuracy: 0.7350 - val_loss: 0.9175\n",
            "Epoch 140/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.7817 - loss: 0.5243 - val_accuracy: 0.7094 - val_loss: 0.8739\n",
            "Epoch 141/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8206 - loss: 0.4981 - val_accuracy: 0.7265 - val_loss: 0.8520\n",
            "Epoch 142/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7941 - loss: 0.5071 - val_accuracy: 0.7265 - val_loss: 0.9064\n",
            "Epoch 143/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8013 - loss: 0.4991 - val_accuracy: 0.7265 - val_loss: 0.9005\n",
            "Epoch 144/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7673 - loss: 0.5201 - val_accuracy: 0.7179 - val_loss: 0.9040\n",
            "Epoch 145/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.7546 - loss: 0.5511 - val_accuracy: 0.7179 - val_loss: 0.9081\n",
            "Epoch 146/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.7869 - loss: 0.5378 - val_accuracy: 0.7350 - val_loss: 0.7952\n",
            "Epoch 147/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.8382 - loss: 0.4538 - val_accuracy: 0.7350 - val_loss: 0.8467\n",
            "Epoch 148/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - accuracy: 0.7819 - loss: 0.5299 - val_accuracy: 0.7436 - val_loss: 0.7910\n",
            "Epoch 149/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 307ms/step - accuracy: 0.7770 - loss: 0.5343 - val_accuracy: 0.7265 - val_loss: 0.9510\n",
            "Epoch 150/150\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 242ms/step - accuracy: 0.8055 - loss: 0.4448 - val_accuracy: 0.7350 - val_loss: 0.9213\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x243c9441030>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "num_epochs = 150\n",
        "num_batch_size = 32\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e73b4c8f",
      "metadata": {
        "id": "e73b4c8f",
        "outputId": "e5adc8fe-2e56-401b-b2d1-e434c95c2b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7471 - loss: 0.7920\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7350427508354187"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=1)\n",
        "acc_bilstm = test_accuracy[1]\n",
        "acc_bilstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581c5075",
      "metadata": {
        "scrolled": true,
        "id": "581c5075",
        "outputId": "67afd0f3-61ee-4764-bb72-6bc8eef45ffe"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "positional argument follows keyword argument (3772781728.py, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[42], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = Sequential([Conv1D(128, 3, activation='relu',MaxPooling1D(2),Conv1D(64, 3, activation='relu'),MaxPooling1D(2),Flatten(),Dense(32, activation='relu'),Dense(5, activation='softmax'))\u001b[0m\n\u001b[1;37m                                                                                                                                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "model = Sequential([Conv1D(128, 3, activation='relu',MaxPooling1D(2),Conv1D(64, 3, activation='relu'),MaxPooling1D(2),Flatten(),Dense(32, activation='relu'),Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4942c768",
      "metadata": {
        "scrolled": true,
        "id": "4942c768",
        "outputId": "7c0d6b74-56fa-4c3b-b235-93b9b5a1e8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[67], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      2\u001b[0m num_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:546\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m     )\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
            "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 5)"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "num_epochs = 200\n",
        "num_batch_size = 32\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d0967a",
      "metadata": {
        "id": "82d0967a"
      },
      "outputs": [],
      "source": [
        "#model=Sequential()\n",
        "#model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "#model.add(LSTM(128, activation='relu'))\n",
        "#model.add(Dense(32, activation='relu'))\n",
        "#model.add(Dense(5, activation='softmax'))\n",
        "model = Sequential([LSTM(128, activation='relu', return_sequences=True),LSTM(128), Dense(5, activation='softmax')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725b53a1",
      "metadata": {
        "id": "725b53a1"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30fd0d77",
      "metadata": {
        "scrolled": true,
        "id": "30fd0d77",
        "outputId": "c198cb3a-02db-4a22-88f3-56dc8027550f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14420\\1142117630.py\", line 4, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,5] and labels shape [160]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_24092]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[98], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      3\u001b[0m num_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14420\\1142117630.py\", line 4, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1127, in train_step\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,5] and labels shape [160]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_24092]"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "num_epochs = 200\n",
        "num_batch_size = 32\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4f00a6e",
      "metadata": {
        "scrolled": true,
        "id": "b4f00a6e",
        "outputId": "d7f91120-695b-404b-b781-147a0486ea7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 30ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted = model.predict(X_test)\n",
        "import numpy as np\n",
        "np.argmax(predicted[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0277d40e",
      "metadata": {
        "id": "0277d40e",
        "outputId": "0455c36f-de33-4b5e-ef7c-7441ad0f890b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1], dtype=uint8)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b02bff4",
      "metadata": {
        "id": "3b02bff4",
        "outputId": "dc9cbe2d-95d7-4409-a24b-04b30622ee22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 33ms/step - loss: 0.6758 - accuracy: 0.7265\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7264957427978516"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=1)\n",
        "acc_rnn = test_accuracy[1]\n",
        "acc_rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e78b5d",
      "metadata": {
        "id": "f1e78b5d",
        "outputId": "b96b04f3-dea6-4c27-d2a1-52e1e7e13889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### No of classes\n",
        "num_labels=y.shape[1]\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72993bd",
      "metadata": {
        "id": "b72993bd"
      },
      "outputs": [],
      "source": [
        "#normalization\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c9658f",
      "metadata": {
        "id": "f2c9658f"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(100,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###second layer\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###third layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "###final layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45bf2c6b",
      "metadata": {
        "scrolled": true,
        "id": "45bf2c6b",
        "outputId": "68515dfb-6e8c-4d8e-924d-e78911650db1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                       </span><span style=\"font-weight: bold\"> Output Shape                  </span><span style=\"font-weight: bold\">     Param # </span>\n",
              "\n",
              " dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> \n",
              "\n",
              " activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> \n",
              "\n",
              " activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> \n",
              "\n",
              " activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> \n",
              "\n",
              " activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_20 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                          \u001b[38;5;34m4,100\u001b[0m \n",
              "\n",
              " activation_4 (\u001b[38;5;33mActivation\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_21 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                         \u001b[38;5;34m20,200\u001b[0m \n",
              "\n",
              " activation_5 (\u001b[38;5;33mActivation\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_22 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                         \u001b[38;5;34m20,100\u001b[0m \n",
              "\n",
              " activation_6 (\u001b[38;5;33mActivation\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_23 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                              \u001b[38;5;34m505\u001b[0m \n",
              "\n",
              " activation_7 (\u001b[38;5;33mActivation\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,905</span> (175.41 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,905\u001b[0m (175.41 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,905</span> (175.41 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,905\u001b[0m (175.41 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2876a230",
      "metadata": {
        "id": "2876a230",
        "outputId": "c3319b6c-93a1-4fc6-8eea-47773e53d24b"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Cannot clone object '<keras.src.engine.sequential.Sequential object at 0x000001A455DC87F0>' (type <class 'keras.src.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, hyperparameters, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model to the training data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Print the best set of hyperparameters\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:788\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    785\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    786\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[1;32m--> 788\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch)\n\u001b[0;32m    792\u001b[0m fit_and_score_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    793\u001b[0m     scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    794\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    800\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    801\u001b[0m )\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:79\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     74\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should provide an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn estimator instead of a class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[0;32m     84\u001b[0m             )\n\u001b[0;32m     86\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[0;32m     87\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.src.engine.sequential.Sequential object at 0x000001A455DC87F0>' (type <class 'keras.src.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "hyperparameters = {\n",
        "    'optimizer': ['adam', 'rmsprop'],\n",
        "    'loss': ['binary_crossentropy', 'categorical_crossentropy'],\n",
        "    'epochs': [10, 20, 30],\n",
        "    'batch_size': [32, 64, 128],\n",
        "}\n",
        "\n",
        "# Create a randomized search object\n",
        "random_search = RandomizedSearchCV(model, hyperparameters, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = random_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81bee6a",
      "metadata": {
        "id": "c81bee6a"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8501533b",
      "metadata": {
        "scrolled": true,
        "id": "8501533b",
        "outputId": "fdee0425-1b10-4c15-fad1-a2b320cf4179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m 9/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4323 - loss: 48.4593\n",
            "Epoch 1: val_loss improved from inf to 11.34848, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.4350 - loss: 46.5629 - val_accuracy: 0.5812 - val_loss: 11.3485\n",
            "Epoch 2/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4070 - loss: 28.0918 \n",
            "Epoch 2: val_loss improved from 11.34848 to 6.07246, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4039 - loss: 27.4466 - val_accuracy: 0.5641 - val_loss: 6.0725\n",
            "Epoch 3/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4261 - loss: 20.1617 \n",
            "Epoch 3: val_loss improved from 6.07246 to 3.05772, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4246 - loss: 20.0458 - val_accuracy: 0.5299 - val_loss: 3.0577\n",
            "Epoch 4/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4015 - loss: 15.3512 \n",
            "Epoch 4: val_loss improved from 3.05772 to 1.99875, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4052 - loss: 15.0909 - val_accuracy: 0.5641 - val_loss: 1.9987\n",
            "Epoch 5/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4723 - loss: 11.8004 \n",
            "Epoch 5: val_loss improved from 1.99875 to 1.25055, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4715 - loss: 11.7410 - val_accuracy: 0.5897 - val_loss: 1.2506\n",
            "Epoch 6/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4371 - loss: 9.6047  \n",
            "Epoch 6: val_loss improved from 1.25055 to 1.18038, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4386 - loss: 9.4517 - val_accuracy: 0.4444 - val_loss: 1.1804\n",
            "Epoch 7/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4162 - loss: 6.8188 \n",
            "Epoch 7: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4167 - loss: 6.7888 - val_accuracy: 0.5812 - val_loss: 1.2248\n",
            "Epoch 8/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4707 - loss: 5.2522 \n",
            "Epoch 8: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4635 - loss: 5.3282 - val_accuracy: 0.5470 - val_loss: 1.2141\n",
            "Epoch 9/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4173 - loss: 5.4104 \n",
            "Epoch 9: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4240 - loss: 5.3333 - val_accuracy: 0.5641 - val_loss: 1.3236\n",
            "Epoch 10/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4943 - loss: 3.7756 \n",
            "Epoch 10: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4849 - loss: 3.8584 - val_accuracy: 0.5641 - val_loss: 1.4621\n",
            "Epoch 11/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4329 - loss: 3.9963 \n",
            "Epoch 11: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4325 - loss: 3.9705 - val_accuracy: 0.3761 - val_loss: 1.5189\n",
            "Epoch 12/200\n",
            "\u001b[1m11/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4272 - loss: 3.3862 \n",
            "Epoch 12: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4273 - loss: 3.4302 - val_accuracy: 0.5641 - val_loss: 1.4605\n",
            "Epoch 13/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4559 - loss: 3.1461 \n",
            "Epoch 13: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4598 - loss: 3.0837 - val_accuracy: 0.5641 - val_loss: 1.4923\n",
            "Epoch 14/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3995 - loss: 3.0041 \n",
            "Epoch 14: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4067 - loss: 2.9540 - val_accuracy: 0.5641 - val_loss: 1.4782\n",
            "Epoch 15/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4668 - loss: 2.6078 \n",
            "Epoch 15: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4669 - loss: 2.6016 - val_accuracy: 0.5641 - val_loss: 1.4983\n",
            "Epoch 16/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4055 - loss: 2.4862 \n",
            "Epoch 16: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4069 - loss: 2.4754 - val_accuracy: 0.5641 - val_loss: 1.5101\n",
            "Epoch 17/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4311 - loss: 2.4001 \n",
            "Epoch 17: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4338 - loss: 2.3724 - val_accuracy: 0.5641 - val_loss: 1.4754\n",
            "Epoch 18/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4549 - loss: 2.4318 \n",
            "Epoch 18: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4576 - loss: 2.3864 - val_accuracy: 0.5641 - val_loss: 1.4581\n",
            "Epoch 19/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4911 - loss: 1.7298 \n",
            "Epoch 19: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4950 - loss: 1.7620 - val_accuracy: 0.5641 - val_loss: 1.4742\n",
            "Epoch 20/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5236 - loss: 2.0167 \n",
            "Epoch 20: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5188 - loss: 2.0166 - val_accuracy: 0.5641 - val_loss: 1.4571\n",
            "Epoch 21/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4850 - loss: 1.7367 \n",
            "Epoch 21: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4883 - loss: 1.7220 - val_accuracy: 0.5641 - val_loss: 1.4659\n",
            "Epoch 22/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5509 - loss: 1.6088 \n",
            "Epoch 22: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5480 - loss: 1.6171 - val_accuracy: 0.5641 - val_loss: 1.4512\n",
            "Epoch 23/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5322 - loss: 1.5738 \n",
            "Epoch 23: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5316 - loss: 1.5778 - val_accuracy: 0.5641 - val_loss: 1.4451\n",
            "Epoch 24/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5845 - loss: 1.5379 \n",
            "Epoch 24: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5791 - loss: 1.5573 - val_accuracy: 0.5641 - val_loss: 1.4090\n",
            "Epoch 25/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5712 - loss: 1.6964 \n",
            "Epoch 25: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5700 - loss: 1.6844 - val_accuracy: 0.5641 - val_loss: 1.3896\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5341 - loss: 1.4258 \n",
            "Epoch 26: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5357 - loss: 1.4414 - val_accuracy: 0.5641 - val_loss: 1.3590\n",
            "Epoch 27/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5577 - loss: 1.3030 \n",
            "Epoch 27: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5560 - loss: 1.3340 - val_accuracy: 0.5641 - val_loss: 1.3589\n",
            "Epoch 28/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5439 - loss: 1.6636 \n",
            "Epoch 28: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5478 - loss: 1.6366 - val_accuracy: 0.5641 - val_loss: 1.3321\n",
            "Epoch 29/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 1.4426 \n",
            "Epoch 29: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6123 - loss: 1.4420 - val_accuracy: 0.5641 - val_loss: 1.2830\n",
            "Epoch 30/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 1.3092 \n",
            "Epoch 30: val_loss did not improve from 1.18038\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5463 - loss: 1.3186 - val_accuracy: 0.5641 - val_loss: 1.2182\n",
            "Epoch 31/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5342 - loss: 1.3737 \n",
            "Epoch 31: val_loss improved from 1.18038 to 1.17460, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5397 - loss: 1.3806 - val_accuracy: 0.5641 - val_loss: 1.1746\n",
            "Epoch 32/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5303 - loss: 1.5565 \n",
            "Epoch 32: val_loss did not improve from 1.17460\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 1.5499 - val_accuracy: 0.5641 - val_loss: 1.1968\n",
            "Epoch 33/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5844 - loss: 1.2338 \n",
            "Epoch 33: val_loss did not improve from 1.17460\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5843 - loss: 1.2343 - val_accuracy: 0.5641 - val_loss: 1.1978\n",
            "Epoch 34/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5640 - loss: 1.4553 \n",
            "Epoch 34: val_loss did not improve from 1.17460\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5687 - loss: 1.4415 - val_accuracy: 0.5641 - val_loss: 1.1803\n",
            "Epoch 35/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5808 - loss: 1.2885 \n",
            "Epoch 35: val_loss improved from 1.17460 to 1.15828, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5816 - loss: 1.2857 - val_accuracy: 0.5641 - val_loss: 1.1583\n",
            "Epoch 36/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5629 - loss: 1.1991 \n",
            "Epoch 36: val_loss improved from 1.15828 to 1.13920, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5636 - loss: 1.2026 - val_accuracy: 0.5641 - val_loss: 1.1392\n",
            "Epoch 37/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6204 - loss: 1.2098 \n",
            "Epoch 37: val_loss did not improve from 1.13920\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6200 - loss: 1.2121 - val_accuracy: 0.5641 - val_loss: 1.1537\n",
            "Epoch 38/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 1.2169 \n",
            "Epoch 38: val_loss did not improve from 1.13920\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6258 - loss: 1.2220 - val_accuracy: 0.5641 - val_loss: 1.1658\n",
            "Epoch 39/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 1.2392 \n",
            "Epoch 39: val_loss did not improve from 1.13920\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5861 - loss: 1.2380 - val_accuracy: 0.5641 - val_loss: 1.1618\n",
            "Epoch 40/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6036 - loss: 1.2770 \n",
            "Epoch 40: val_loss improved from 1.13920 to 1.13202, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6031 - loss: 1.2758 - val_accuracy: 0.5641 - val_loss: 1.1320\n",
            "Epoch 41/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5895 - loss: 1.1535 \n",
            "Epoch 41: val_loss improved from 1.13202 to 1.08371, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5880 - loss: 1.1606 - val_accuracy: 0.5641 - val_loss: 1.0837\n",
            "Epoch 42/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5871 - loss: 1.1807 \n",
            "Epoch 42: val_loss improved from 1.08371 to 1.07142, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5884 - loss: 1.1858 - val_accuracy: 0.5641 - val_loss: 1.0714\n",
            "Epoch 43/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 1.1918 \n",
            "Epoch 43: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6227 - loss: 1.1946 - val_accuracy: 0.5641 - val_loss: 1.0837\n",
            "Epoch 44/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5974 - loss: 1.2599 \n",
            "Epoch 44: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5975 - loss: 1.2506 - val_accuracy: 0.5641 - val_loss: 1.0860\n",
            "Epoch 45/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5967 - loss: 1.2367 \n",
            "Epoch 45: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5975 - loss: 1.2345 - val_accuracy: 0.5641 - val_loss: 1.1071\n",
            "Epoch 46/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5754 - loss: 1.3423 \n",
            "Epoch 46: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5842 - loss: 1.3072 - val_accuracy: 0.5641 - val_loss: 1.0958\n",
            "Epoch 47/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5713 - loss: 1.2265 \n",
            "Epoch 47: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5761 - loss: 1.2203 - val_accuracy: 0.5641 - val_loss: 1.0978\n",
            "Epoch 48/200\n",
            "\u001b[1m11/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6069 - loss: 1.1544 \n",
            "Epoch 48: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6078 - loss: 1.1537 - val_accuracy: 0.5641 - val_loss: 1.1010\n",
            "Epoch 49/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5906 - loss: 1.2410 \n",
            "Epoch 49: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5921 - loss: 1.2269 - val_accuracy: 0.5641 - val_loss: 1.0993\n",
            "Epoch 50/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 1.1900 \n",
            "Epoch 50: val_loss did not improve from 1.07142\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6061 - loss: 1.1800 - val_accuracy: 0.5641 - val_loss: 1.0879\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 1.1249 \n",
            "Epoch 51: val_loss improved from 1.07142 to 1.05544, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6161 - loss: 1.1223 - val_accuracy: 0.5641 - val_loss: 1.0554\n",
            "Epoch 52/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6875 - loss: 0.9596\n",
            "Epoch 52: val_loss improved from 1.05544 to 1.04755, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6548 - loss: 1.0405 - val_accuracy: 0.5641 - val_loss: 1.0475\n",
            "Epoch 53/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5894 - loss: 1.2452 \n",
            "Epoch 53: val_loss improved from 1.04755 to 1.03525, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5908 - loss: 1.2310 - val_accuracy: 0.5641 - val_loss: 1.0352\n",
            "Epoch 54/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 1.0944 \n",
            "Epoch 54: val_loss did not improve from 1.03525\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6275 - loss: 1.0980 - val_accuracy: 0.5641 - val_loss: 1.0383\n",
            "Epoch 55/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 1.1111 \n",
            "Epoch 55: val_loss improved from 1.03525 to 1.03287, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5940 - loss: 1.1090 - val_accuracy: 0.5641 - val_loss: 1.0329\n",
            "Epoch 56/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6300 - loss: 1.1324 \n",
            "Epoch 56: val_loss did not improve from 1.03287\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6275 - loss: 1.1349 - val_accuracy: 0.5641 - val_loss: 1.0391\n",
            "Epoch 57/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6222 - loss: 1.0813 \n",
            "Epoch 57: val_loss did not improve from 1.03287\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6237 - loss: 1.0749 - val_accuracy: 0.5641 - val_loss: 1.0331\n",
            "Epoch 58/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6292 - loss: 1.0464 \n",
            "Epoch 58: val_loss did not improve from 1.03287\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6253 - loss: 1.0560 - val_accuracy: 0.5641 - val_loss: 1.0343\n",
            "Epoch 59/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 1.0593 \n",
            "Epoch 59: val_loss did not improve from 1.03287\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6108 - loss: 1.0585 - val_accuracy: 0.5641 - val_loss: 1.0353\n",
            "Epoch 60/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6519 - loss: 1.0305 \n",
            "Epoch 60: val_loss improved from 1.03287 to 1.02647, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6495 - loss: 1.0373 - val_accuracy: 0.5641 - val_loss: 1.0265\n",
            "Epoch 61/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5906 - loss: 1.0671 \n",
            "Epoch 61: val_loss improved from 1.02647 to 1.02164, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5938 - loss: 1.0643 - val_accuracy: 0.5641 - val_loss: 1.0216\n",
            "Epoch 62/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 1.0377 \n",
            "Epoch 62: val_loss improved from 1.02164 to 1.01635, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6482 - loss: 1.0417 - val_accuracy: 0.5641 - val_loss: 1.0163\n",
            "Epoch 63/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6286 - loss: 1.0463 \n",
            "Epoch 63: val_loss improved from 1.01635 to 1.00989, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6297 - loss: 1.0451 - val_accuracy: 0.5641 - val_loss: 1.0099\n",
            "Epoch 64/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5740 - loss: 1.2066 \n",
            "Epoch 64: val_loss did not improve from 1.00989\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5843 - loss: 1.1940 - val_accuracy: 0.5641 - val_loss: 1.0119\n",
            "Epoch 65/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6150 - loss: 1.0478 \n",
            "Epoch 65: val_loss improved from 1.00989 to 0.99365, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6177 - loss: 1.0481 - val_accuracy: 0.5641 - val_loss: 0.9936\n",
            "Epoch 66/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 1.0316 \n",
            "Epoch 66: val_loss improved from 0.99365 to 0.97753, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6345 - loss: 1.0323 - val_accuracy: 0.5726 - val_loss: 0.9775\n",
            "Epoch 67/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 0.9504 \n",
            "Epoch 67: val_loss did not improve from 0.97753\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6306 - loss: 0.9626 - val_accuracy: 0.5641 - val_loss: 0.9890\n",
            "Epoch 68/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 1.0041 \n",
            "Epoch 68: val_loss did not improve from 0.97753\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6544 - loss: 1.0055 - val_accuracy: 0.5641 - val_loss: 0.9941\n",
            "Epoch 69/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: 1.0078 \n",
            "Epoch 69: val_loss did not improve from 0.97753\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6403 - loss: 1.0141 - val_accuracy: 0.5641 - val_loss: 0.9934\n",
            "Epoch 70/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6141 - loss: 1.0388 \n",
            "Epoch 70: val_loss did not improve from 0.97753\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 1.0385 - val_accuracy: 0.5641 - val_loss: 0.9949\n",
            "Epoch 71/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 1.0705 \n",
            "Epoch 71: val_loss did not improve from 0.97753\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6142 - loss: 1.0694 - val_accuracy: 0.5726 - val_loss: 0.9890\n",
            "Epoch 72/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 1.0937 \n",
            "Epoch 72: val_loss did not improve from 0.97753\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6232 - loss: 1.0917 - val_accuracy: 0.5726 - val_loss: 0.9814\n",
            "Epoch 73/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6339 - loss: 0.9717\n",
            "Epoch 73: val_loss improved from 0.97753 to 0.96632, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6335 - loss: 0.9823 - val_accuracy: 0.5726 - val_loss: 0.9663\n",
            "Epoch 74/200\n",
            "\u001b[1m10/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6328 - loss: 1.0342 \n",
            "Epoch 74: val_loss improved from 0.96632 to 0.95380, saving model to saved_models/mul_classification.keras\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6369 - loss: 1.0265 - val_accuracy: 0.6068 - val_loss: 0.9538\n",
            "Epoch 75/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6377 - loss: 1.0830\n",
            "Epoch 75: val_loss improved from 0.95380 to 0.94991, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6365 - loss: 1.0787 - val_accuracy: 0.5812 - val_loss: 0.9499\n",
            "Epoch 76/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6431 - loss: 0.9609 \n",
            "Epoch 76: val_loss improved from 0.94991 to 0.94605, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6423 - loss: 0.9645 - val_accuracy: 0.6068 - val_loss: 0.9460\n",
            "Epoch 77/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6149 - loss: 1.0768 \n",
            "Epoch 77: val_loss improved from 0.94605 to 0.93251, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6162 - loss: 1.0754 - val_accuracy: 0.6154 - val_loss: 0.9325\n",
            "Epoch 78/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6364 - loss: 0.9639 \n",
            "Epoch 78: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6345 - loss: 0.9682 - val_accuracy: 0.5812 - val_loss: 0.9576\n",
            "Epoch 79/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.9038\n",
            "Epoch 79: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6327 - loss: 1.0141 - val_accuracy: 0.5812 - val_loss: 0.9770\n",
            "Epoch 80/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.9495\n",
            "Epoch 80: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6640 - loss: 0.9536 - val_accuracy: 0.5726 - val_loss: 0.9736\n",
            "Epoch 81/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5625 - loss: 1.0395\n",
            "Epoch 81: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6431 - loss: 0.9426 - val_accuracy: 0.5897 - val_loss: 0.9576\n",
            "Epoch 82/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 0.9000 \n",
            "Epoch 82: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6537 - loss: 0.9121 - val_accuracy: 0.5897 - val_loss: 0.9537\n",
            "Epoch 83/200\n",
            "\u001b[1m 8/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6214 - loss: 0.9957  \n",
            "Epoch 83: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6268 - loss: 0.9851 - val_accuracy: 0.5897 - val_loss: 0.9563\n",
            "Epoch 84/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6562 - loss: 0.8641\n",
            "Epoch 84: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6414 - loss: 0.9652 - val_accuracy: 0.6068 - val_loss: 0.9415\n",
            "Epoch 85/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6207 - loss: 1.0205 \n",
            "Epoch 85: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6239 - loss: 1.0241 - val_accuracy: 0.5983 - val_loss: 0.9448\n",
            "Epoch 86/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5312 - loss: 1.0841\n",
            "Epoch 86: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6172 - loss: 1.0093 - val_accuracy: 0.5983 - val_loss: 0.9466\n",
            "Epoch 87/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6562 - loss: 0.8164\n",
            "Epoch 87: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6505 - loss: 0.9138 - val_accuracy: 0.5983 - val_loss: 0.9429\n",
            "Epoch 88/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5312 - loss: 1.1245\n",
            "Epoch 88: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6227 - loss: 0.9696 - val_accuracy: 0.5983 - val_loss: 0.9409\n",
            "Epoch 89/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5312 - loss: 0.9391\n",
            "Epoch 89: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5819 - loss: 0.9941 - val_accuracy: 0.5897 - val_loss: 0.9393\n",
            "Epoch 90/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5938 - loss: 1.0883\n",
            "Epoch 90: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6257 - loss: 1.0549 - val_accuracy: 0.5812 - val_loss: 0.9491\n",
            "Epoch 91/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.9658 \n",
            "Epoch 91: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6473 - loss: 0.9649 - val_accuracy: 0.5897 - val_loss: 0.9486\n",
            "Epoch 92/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 0.9842 \n",
            "Epoch 92: val_loss did not improve from 0.93251\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6233 - loss: 0.9804 - val_accuracy: 0.5897 - val_loss: 0.9353\n",
            "Epoch 93/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7188 - loss: 0.8536\n",
            "Epoch 93: val_loss improved from 0.93251 to 0.92802, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6714 - loss: 0.9308 - val_accuracy: 0.6154 - val_loss: 0.9280\n",
            "Epoch 94/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.9283 \n",
            "Epoch 94: val_loss did not improve from 0.92802\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6575 - loss: 0.9288 - val_accuracy: 0.6154 - val_loss: 0.9302\n",
            "Epoch 95/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.9094 \n",
            "Epoch 95: val_loss improved from 0.92802 to 0.92146, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6751 - loss: 0.9157 - val_accuracy: 0.6410 - val_loss: 0.9215\n",
            "Epoch 96/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6875 - loss: 0.8071\n",
            "Epoch 96: val_loss improved from 0.92146 to 0.92067, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6393 - loss: 0.9859 - val_accuracy: 0.6154 - val_loss: 0.9207\n",
            "Epoch 97/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.8881  \n",
            "Epoch 97: val_loss did not improve from 0.92067\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6680 - loss: 0.8968 - val_accuracy: 0.6154 - val_loss: 0.9267\n",
            "Epoch 98/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.9609 \n",
            "Epoch 98: val_loss did not improve from 0.92067\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6361 - loss: 0.9630 - val_accuracy: 0.6068 - val_loss: 0.9354\n",
            "Epoch 99/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6298 - loss: 0.9491 \n",
            "Epoch 99: val_loss did not improve from 0.92067\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6337 - loss: 0.9449 - val_accuracy: 0.5983 - val_loss: 0.9381\n",
            "Epoch 100/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.8825 \n",
            "Epoch 100: val_loss did not improve from 0.92067\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6855 - loss: 0.8964 - val_accuracy: 0.6154 - val_loss: 0.9214\n",
            "Epoch 101/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6562 - loss: 0.9095\n",
            "Epoch 101: val_loss did not improve from 0.92067\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - loss: 0.9570 - val_accuracy: 0.6154 - val_loss: 0.9395\n",
            "Epoch 102/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 1.1254\n",
            "Epoch 102: val_loss did not improve from 0.92067\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6495 - loss: 0.9336 - val_accuracy: 0.6239 - val_loss: 0.9340\n",
            "Epoch 103/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6111 - loss: 0.9638 \n",
            "Epoch 103: val_loss improved from 0.92067 to 0.91978, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6127 - loss: 0.9623 - val_accuracy: 0.6154 - val_loss: 0.9198\n",
            "Epoch 104/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6562 - loss: 0.9044\n",
            "Epoch 104: val_loss improved from 0.91978 to 0.91837, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6564 - loss: 0.9369 - val_accuracy: 0.6154 - val_loss: 0.9184\n",
            "Epoch 105/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5312 - loss: 0.9925\n",
            "Epoch 105: val_loss improved from 0.91837 to 0.91819, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6649 - loss: 0.8870 - val_accuracy: 0.6154 - val_loss: 0.9182\n",
            "Epoch 106/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6606 - loss: 0.9486 \n",
            "Epoch 106: val_loss improved from 0.91819 to 0.91017, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6592 - loss: 0.9495 - val_accuracy: 0.6239 - val_loss: 0.9102\n",
            "Epoch 107/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6622 - loss: 0.9106 \n",
            "Epoch 107: val_loss improved from 0.91017 to 0.90459, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6609 - loss: 0.9116 - val_accuracy: 0.6325 - val_loss: 0.9046\n",
            "Epoch 108/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 1.0225\n",
            "Epoch 108: val_loss improved from 0.90459 to 0.90128, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6552 - loss: 0.9349 - val_accuracy: 0.6325 - val_loss: 0.9013\n",
            "Epoch 109/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6417 - loss: 0.9886 \n",
            "Epoch 109: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6414 - loss: 0.9859 - val_accuracy: 0.6239 - val_loss: 0.9166\n",
            "Epoch 110/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.8442\n",
            "Epoch 110: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6294 - loss: 0.9758 - val_accuracy: 0.6154 - val_loss: 0.9202\n",
            "Epoch 111/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5625 - loss: 1.0332\n",
            "Epoch 111: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6345 - loss: 0.9520 - val_accuracy: 0.6154 - val_loss: 0.9112\n",
            "Epoch 112/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6875 - loss: 0.8457\n",
            "Epoch 112: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6664 - loss: 0.9309 - val_accuracy: 0.6154 - val_loss: 0.9112\n",
            "Epoch 113/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.9377 \n",
            "Epoch 113: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6331 - loss: 0.9401 - val_accuracy: 0.6325 - val_loss: 0.9132\n",
            "Epoch 114/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6827 - loss: 0.8832 \n",
            "Epoch 114: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6816 - loss: 0.8846 - val_accuracy: 0.6410 - val_loss: 0.9013\n",
            "Epoch 115/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6496 - loss: 0.9041 \n",
            "Epoch 115: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6504 - loss: 0.9057 - val_accuracy: 0.6325 - val_loss: 0.9060\n",
            "Epoch 116/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6562 - loss: 1.0894\n",
            "Epoch 116: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6636 - loss: 0.9339 - val_accuracy: 0.6239 - val_loss: 0.9086\n",
            "Epoch 117/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.8756\n",
            "Epoch 117: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6339 - loss: 0.9519 - val_accuracy: 0.6325 - val_loss: 0.9035\n",
            "Epoch 118/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 0.8823 \n",
            "Epoch 118: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6748 - loss: 0.8846 - val_accuracy: 0.6239 - val_loss: 0.9064\n",
            "Epoch 119/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.9149 \n",
            "Epoch 119: val_loss did not improve from 0.90128\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6779 - loss: 0.9157 - val_accuracy: 0.6154 - val_loss: 0.9097\n",
            "Epoch 120/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6746 - loss: 0.8840 \n",
            "Epoch 120: val_loss improved from 0.90128 to 0.89391, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6728 - loss: 0.8845 - val_accuracy: 0.6410 - val_loss: 0.8939\n",
            "Epoch 121/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7188 - loss: 0.8572\n",
            "Epoch 121: val_loss improved from 0.89391 to 0.88889, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6730 - loss: 0.9079 - val_accuracy: 0.6410 - val_loss: 0.8889\n",
            "Epoch 122/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6638 - loss: 0.8954 \n",
            "Epoch 122: val_loss did not improve from 0.88889\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6638 - loss: 0.8960 - val_accuracy: 0.6325 - val_loss: 0.8988\n",
            "Epoch 123/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.9626 \n",
            "Epoch 123: val_loss did not improve from 0.88889\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6326 - loss: 0.9620 - val_accuracy: 0.6325 - val_loss: 0.9026\n",
            "Epoch 124/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.7315\n",
            "Epoch 124: val_loss did not improve from 0.88889\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6423 - loss: 0.9026 - val_accuracy: 0.6410 - val_loss: 0.8996\n",
            "Epoch 125/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.9298 \n",
            "Epoch 125: val_loss improved from 0.88889 to 0.88588, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6316 - loss: 0.9276 - val_accuracy: 0.6410 - val_loss: 0.8859\n",
            "Epoch 126/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8125 - loss: 0.7361\n",
            "Epoch 126: val_loss did not improve from 0.88588\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6820 - loss: 0.8646 - val_accuracy: 0.6325 - val_loss: 0.8943\n",
            "Epoch 127/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5625 - loss: 0.8813\n",
            "Epoch 127: val_loss did not improve from 0.88588\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6331 - loss: 0.9034 - val_accuracy: 0.6239 - val_loss: 0.8891\n",
            "Epoch 128/200\n",
            "\u001b[1m 7/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6332 - loss: 0.9989 \n",
            "Epoch 128: val_loss improved from 0.88588 to 0.87985, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6420 - loss: 0.9629 - val_accuracy: 0.6410 - val_loss: 0.8799\n",
            "Epoch 129/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6923 - loss: 0.8869 \n",
            "Epoch 129: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6864 - loss: 0.8972 - val_accuracy: 0.6410 - val_loss: 0.8832\n",
            "Epoch 130/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 0.9013 \n",
            "Epoch 130: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6451 - loss: 0.9039 - val_accuracy: 0.6325 - val_loss: 0.9006\n",
            "Epoch 131/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6728 - loss: 0.9428 \n",
            "Epoch 131: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6689 - loss: 0.9414 - val_accuracy: 0.6154 - val_loss: 0.9167\n",
            "Epoch 132/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6397 - loss: 0.9125 \n",
            "Epoch 132: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6417 - loss: 0.9133 - val_accuracy: 0.6325 - val_loss: 0.8995\n",
            "Epoch 133/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6515 - loss: 0.8898 \n",
            "Epoch 133: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6499 - loss: 0.8933 - val_accuracy: 0.6410 - val_loss: 0.8923\n",
            "Epoch 134/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.9603 \n",
            "Epoch 134: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6305 - loss: 0.9609 - val_accuracy: 0.6410 - val_loss: 0.8924\n",
            "Epoch 135/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6782 - loss: 0.8726 \n",
            "Epoch 135: val_loss did not improve from 0.87985\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6769 - loss: 0.8739 - val_accuracy: 0.6410 - val_loss: 0.9031\n",
            "Epoch 136/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6904 - loss: 0.8993 \n",
            "Epoch 136: val_loss improved from 0.87985 to 0.87912, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6855 - loss: 0.9032 - val_accuracy: 0.6410 - val_loss: 0.8791\n",
            "Epoch 137/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6422 - loss: 0.9163 \n",
            "Epoch 137: val_loss improved from 0.87912 to 0.87899, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6432 - loss: 0.9153 - val_accuracy: 0.6410 - val_loss: 0.8790\n",
            "Epoch 138/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6363 - loss: 0.9668  \n",
            "Epoch 138: val_loss did not improve from 0.87899\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6399 - loss: 0.9572 - val_accuracy: 0.6068 - val_loss: 0.9092\n",
            "Epoch 139/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8438 - loss: 0.6305\n",
            "Epoch 139: val_loss did not improve from 0.87899\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6826 - loss: 0.8475 - val_accuracy: 0.6068 - val_loss: 0.9012\n",
            "Epoch 140/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6311 - loss: 0.9037 \n",
            "Epoch 140: val_loss did not improve from 0.87899\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6384 - loss: 0.8957 - val_accuracy: 0.6239 - val_loss: 0.8830\n",
            "Epoch 141/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6812 - loss: 0.8456 \n",
            "Epoch 141: val_loss improved from 0.87899 to 0.86565, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6802 - loss: 0.8497 - val_accuracy: 0.6410 - val_loss: 0.8657\n",
            "Epoch 142/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 0.7950\n",
            "Epoch 142: val_loss improved from 0.86565 to 0.86066, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6636 - loss: 0.8889 - val_accuracy: 0.6496 - val_loss: 0.8607\n",
            "Epoch 143/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.8454 \n",
            "Epoch 143: val_loss did not improve from 0.86066\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6717 - loss: 0.8494 - val_accuracy: 0.6410 - val_loss: 0.8708\n",
            "Epoch 144/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7188 - loss: 0.7626\n",
            "Epoch 144: val_loss did not improve from 0.86066\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7048 - loss: 0.8231 - val_accuracy: 0.6410 - val_loss: 0.8818\n",
            "Epoch 145/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6727 - loss: 0.8645 \n",
            "Epoch 145: val_loss did not improve from 0.86066\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6722 - loss: 0.8650 - val_accuracy: 0.6410 - val_loss: 0.8825\n",
            "Epoch 146/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6875 - loss: 0.9325\n",
            "Epoch 146: val_loss did not improve from 0.86066\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6548 - loss: 0.9228 - val_accuracy: 0.6410 - val_loss: 0.8707\n",
            "Epoch 147/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6523 - loss: 0.9025 \n",
            "Epoch 147: val_loss improved from 0.86066 to 0.85851, saving model to saved_models/mul_classification.keras\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6542 - loss: 0.8987 - val_accuracy: 0.6410 - val_loss: 0.8585\n",
            "Epoch 148/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.9211\n",
            "Epoch 148: val_loss did not improve from 0.85851\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6551 - loss: 0.8920 - val_accuracy: 0.6410 - val_loss: 0.8634\n",
            "Epoch 149/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 0.9132 \n",
            "Epoch 149: val_loss improved from 0.85851 to 0.85370, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6360 - loss: 0.9115 - val_accuracy: 0.6410 - val_loss: 0.8537\n",
            "Epoch 150/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 0.8884 \n",
            "Epoch 150: val_loss did not improve from 0.85370\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6464 - loss: 0.8943 - val_accuracy: 0.6410 - val_loss: 0.8580\n",
            "Epoch 151/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6250 - loss: 0.8903\n",
            "Epoch 151: val_loss did not improve from 0.85370\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6529 - loss: 0.9013 - val_accuracy: 0.6239 - val_loss: 0.8846\n",
            "Epoch 152/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6612 - loss: 0.9394 \n",
            "Epoch 152: val_loss did not improve from 0.85370\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6609 - loss: 0.9367 - val_accuracy: 0.6410 - val_loss: 0.8631\n",
            "Epoch 153/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7188 - loss: 0.7366\n",
            "Epoch 153: val_loss did not improve from 0.85370\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6756 - loss: 0.8600 - val_accuracy: 0.6410 - val_loss: 0.8595\n",
            "Epoch 154/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7188 - loss: 0.7641\n",
            "Epoch 154: val_loss improved from 0.85370 to 0.85249, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6688 - loss: 0.8584 - val_accuracy: 0.6410 - val_loss: 0.8525\n",
            "Epoch 155/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 1.0868\n",
            "Epoch 155: val_loss improved from 0.85249 to 0.83971, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6335 - loss: 0.9423 - val_accuracy: 0.6496 - val_loss: 0.8397\n",
            "Epoch 156/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6801 - loss: 0.8339 \n",
            "Epoch 156: val_loss improved from 0.83971 to 0.83610, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6768 - loss: 0.8391 - val_accuracy: 0.6496 - val_loss: 0.8361\n",
            "Epoch 157/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7188 - loss: 0.8182\n",
            "Epoch 157: val_loss did not improve from 0.83610\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6652 - loss: 0.8799 - val_accuracy: 0.6496 - val_loss: 0.8460\n",
            "Epoch 158/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.7586\n",
            "Epoch 158: val_loss improved from 0.83610 to 0.82086, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6841 - loss: 0.8465 - val_accuracy: 0.6581 - val_loss: 0.8209\n",
            "Epoch 159/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6721 - loss: 0.8595 \n",
            "Epoch 159: val_loss did not improve from 0.82086\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6733 - loss: 0.8573 - val_accuracy: 0.6496 - val_loss: 0.8323\n",
            "Epoch 160/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.8334 \n",
            "Epoch 160: val_loss did not improve from 0.82086\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6730 - loss: 0.8363 - val_accuracy: 0.6496 - val_loss: 0.8477\n",
            "Epoch 161/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.8380 \n",
            "Epoch 161: val_loss did not improve from 0.82086\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6863 - loss: 0.8458 - val_accuracy: 0.6496 - val_loss: 0.8397\n",
            "Epoch 162/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6577 - loss: 0.8649 \n",
            "Epoch 162: val_loss did not improve from 0.82086\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6604 - loss: 0.8627 - val_accuracy: 0.6496 - val_loss: 0.8235\n",
            "Epoch 163/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6250 - loss: 0.8670\n",
            "Epoch 163: val_loss improved from 0.82086 to 0.81965, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6633 - loss: 0.8659 - val_accuracy: 0.6496 - val_loss: 0.8196\n",
            "Epoch 164/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6618 - loss: 0.8418 \n",
            "Epoch 164: val_loss did not improve from 0.81965\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6632 - loss: 0.8425 - val_accuracy: 0.6496 - val_loss: 0.8355\n",
            "Epoch 165/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6875 - loss: 0.9144\n",
            "Epoch 165: val_loss did not improve from 0.81965\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6874 - loss: 0.8506 - val_accuracy: 0.6496 - val_loss: 0.8248\n",
            "Epoch 166/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6875 - loss: 0.8094\n",
            "Epoch 166: val_loss did not improve from 0.81965\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7041 - loss: 0.8176 - val_accuracy: 0.6410 - val_loss: 0.8289\n",
            "Epoch 167/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.7062\n",
            "Epoch 167: val_loss improved from 0.81965 to 0.81255, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7093 - loss: 0.8016 - val_accuracy: 0.6496 - val_loss: 0.8125\n",
            "Epoch 168/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6944 - loss: 0.8391 \n",
            "Epoch 168: val_loss improved from 0.81255 to 0.80921, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6915 - loss: 0.8413 - val_accuracy: 0.6496 - val_loss: 0.8092\n",
            "Epoch 169/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6817 - loss: 0.8417 \n",
            "Epoch 169: val_loss did not improve from 0.80921\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6806 - loss: 0.8426 - val_accuracy: 0.6410 - val_loss: 0.8184\n",
            "Epoch 170/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6658 - loss: 0.8805 \n",
            "Epoch 170: val_loss improved from 0.80921 to 0.79964, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6670 - loss: 0.8768 - val_accuracy: 0.6496 - val_loss: 0.7996\n",
            "Epoch 171/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6250 - loss: 0.7599\n",
            "Epoch 171: val_loss improved from 0.79964 to 0.78884, saving model to saved_models/mul_classification.keras\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6804 - loss: 0.8163 - val_accuracy: 0.6581 - val_loss: 0.7888\n",
            "Epoch 172/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6830 - loss: 0.8336 \n",
            "Epoch 172: val_loss did not improve from 0.78884\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6829 - loss: 0.8352 - val_accuracy: 0.6752 - val_loss: 0.7912\n",
            "Epoch 173/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6838 - loss: 0.8132 \n",
            "Epoch 173: val_loss did not improve from 0.78884\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6830 - loss: 0.8155 - val_accuracy: 0.7009 - val_loss: 0.7926\n",
            "Epoch 174/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 0.8891 \n",
            "Epoch 174: val_loss did not improve from 0.78884\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6525 - loss: 0.8831 - val_accuracy: 0.6923 - val_loss: 0.7947\n",
            "Epoch 175/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6728 - loss: 0.8968 \n",
            "Epoch 175: val_loss did not improve from 0.78884\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6733 - loss: 0.8962 - val_accuracy: 0.6667 - val_loss: 0.8090\n",
            "Epoch 176/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6902 - loss: 0.8433 \n",
            "Epoch 176: val_loss improved from 0.78884 to 0.78683, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6895 - loss: 0.8411 - val_accuracy: 0.7094 - val_loss: 0.7868\n",
            "Epoch 177/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.7671 \n",
            "Epoch 177: val_loss improved from 0.78683 to 0.77201, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7109 - loss: 0.7715 - val_accuracy: 0.7094 - val_loss: 0.7720\n",
            "Epoch 178/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.8447 \n",
            "Epoch 178: val_loss improved from 0.77201 to 0.76541, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6911 - loss: 0.8452 - val_accuracy: 0.7265 - val_loss: 0.7654\n",
            "Epoch 179/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6551 - loss: 0.9063 \n",
            "Epoch 179: val_loss did not improve from 0.76541\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6558 - loss: 0.9042 - val_accuracy: 0.7094 - val_loss: 0.7693\n",
            "Epoch 180/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6875 - loss: 0.7663\n",
            "Epoch 180: val_loss did not improve from 0.76541\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6665 - loss: 0.8644 - val_accuracy: 0.7094 - val_loss: 0.7716\n",
            "Epoch 181/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6762 - loss: 0.8618 \n",
            "Epoch 181: val_loss improved from 0.76541 to 0.75462, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6794 - loss: 0.8517 - val_accuracy: 0.7094 - val_loss: 0.7546\n",
            "Epoch 182/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6770 - loss: 0.8461 \n",
            "Epoch 182: val_loss did not improve from 0.75462\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6786 - loss: 0.8449 - val_accuracy: 0.7179 - val_loss: 0.7654\n",
            "Epoch 183/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6875 - loss: 1.1149\n",
            "Epoch 183: val_loss did not improve from 0.75462\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6838 - loss: 0.8984 - val_accuracy: 0.7094 - val_loss: 0.7804\n",
            "Epoch 184/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6685 - loss: 0.8414 \n",
            "Epoch 184: val_loss did not improve from 0.75462\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6691 - loss: 0.8408 - val_accuracy: 0.7094 - val_loss: 0.7694\n",
            "Epoch 185/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.6442\n",
            "Epoch 185: val_loss did not improve from 0.75462\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7171 - loss: 0.7832 - val_accuracy: 0.7179 - val_loss: 0.7556\n",
            "Epoch 186/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.8143\n",
            "Epoch 186: val_loss improved from 0.75462 to 0.74455, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7121 - loss: 0.8073 - val_accuracy: 0.7094 - val_loss: 0.7445\n",
            "Epoch 187/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6821 - loss: 0.7963 \n",
            "Epoch 187: val_loss improved from 0.74455 to 0.73792, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6839 - loss: 0.7960 - val_accuracy: 0.7094 - val_loss: 0.7379\n",
            "Epoch 188/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6883 - loss: 0.8187 \n",
            "Epoch 188: val_loss improved from 0.73792 to 0.73276, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6888 - loss: 0.8181 - val_accuracy: 0.7094 - val_loss: 0.7328\n",
            "Epoch 189/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.7359\n",
            "Epoch 189: val_loss did not improve from 0.73276\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6980 - loss: 0.7938 - val_accuracy: 0.7179 - val_loss: 0.7471\n",
            "Epoch 190/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6617 - loss: 0.8660 \n",
            "Epoch 190: val_loss did not improve from 0.73276\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6673 - loss: 0.8566 - val_accuracy: 0.7179 - val_loss: 0.7509\n",
            "Epoch 191/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5938 - loss: 1.4175\n",
            "Epoch 191: val_loss did not improve from 0.73276\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6756 - loss: 0.9216 - val_accuracy: 0.7009 - val_loss: 0.7593\n",
            "Epoch 192/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6875 - loss: 0.8009\n",
            "Epoch 192: val_loss did not improve from 0.73276\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6943 - loss: 0.7936 - val_accuracy: 0.7094 - val_loss: 0.7388\n",
            "Epoch 193/200\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.8400 \n",
            "Epoch 193: val_loss did not improve from 0.73276\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6942 - loss: 0.8405 - val_accuracy: 0.7179 - val_loss: 0.7459\n",
            "Epoch 194/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.8486 \n",
            "Epoch 194: val_loss did not improve from 0.73276\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6726 - loss: 0.8435 - val_accuracy: 0.7179 - val_loss: 0.7425\n",
            "Epoch 195/200\n",
            "\u001b[1m14/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6924 - loss: 0.7878 \n",
            "Epoch 195: val_loss improved from 0.73276 to 0.72701, saving model to saved_models/mul_classification.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6929 - loss: 0.7901 - val_accuracy: 0.7265 - val_loss: 0.7270\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 196/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6562 - loss: 0.7496\n",
            "Epoch 196: val_loss did not improve from 0.72701\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6923 - loss: 0.8428 - val_accuracy: 0.7094 - val_loss: 0.7641\n",
            "Epoch 197/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7188 - loss: 1.5905\n",
            "Epoch 197: val_loss did not improve from 0.72701\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7075 - loss: 0.9627 - val_accuracy: 0.7009 - val_loss: 0.7541\n",
            "Epoch 198/200\n",
            "\u001b[1m13/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6954 - loss: 0.8123 \n",
            "Epoch 198: val_loss did not improve from 0.72701\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6942 - loss: 0.8133 - val_accuracy: 0.7009 - val_loss: 0.7429\n",
            "Epoch 199/200\n",
            "\u001b[1m12/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6884 - loss: 0.8411 \n",
            "Epoch 199: val_loss did not improve from 0.72701\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6903 - loss: 0.8395 - val_accuracy: 0.7009 - val_loss: 0.7455\n",
            "Epoch 200/200\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.9211\n",
            "Epoch 200: val_loss did not improve from 0.72701\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6782 - loss: 0.8182 - val_accuracy: 0.7009 - val_loss: 0.7357\n",
            "Training completed in time:  0:00:38.574340\n"
          ]
        }
      ],
      "source": [
        "#DL Model Training\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "num_epochs = 200\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/mul_classification.keras',\n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a224320a",
      "metadata": {
        "id": "a224320a",
        "outputId": "bb4b8d20-8fcd-4af1-d920-6c27bce5eedc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7435897588729858"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "acc_ann = test_accuracy[1]\n",
        "acc_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40648885",
      "metadata": {
        "id": "40648885",
        "outputId": "303e516f-31f8-45d6-9dcc-5922214b3211"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13780\\3279002212.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n"
          ]
        },
        {
          "ename": "NoBackendError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
            "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'DiptaBeat.wav': Format not recognised.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[72], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m labelencoder\u001b[38;5;241m=\u001b[39mLabelEncoder()\n\u001b[0;32m      4\u001b[0m filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiptaBeat.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkaiser_fast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      6\u001b[0m mfccs_features \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msample_rate, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m      7\u001b[0m mfccs_scaled_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(mfccs_features\u001b[38;5;241m.\u001b[39mT,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:60\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     59\u001b[0m )\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:241\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    238\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    244\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\__init__.py:132\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# All backends failed!\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m NoBackendError()\n",
            "\u001b[1;31mNoBackendError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "labelencoder=LabelEncoder()\n",
        "filename=\"DiptaBeat.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "model = load_model(\"saved_models/mul_classification.hdf5\")\n",
        "#print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "#print(mfccs_scaled_features)\n",
        "#print(mfccs_scaled_features.shape)\n",
        "predicted_label=model.predict(mfccs_scaled_features)\n",
        "ans = predicted_label[0][4]*100\n",
        "#predicted_label\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147437ba",
      "metadata": {
        "id": "147437ba"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}